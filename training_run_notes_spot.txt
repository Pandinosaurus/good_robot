





Tab 7: ~/src/CoppeliaSim_Edu_V4_0_0_Ubuntu18_04/coppeliaSim.sh -gREMOTEAPISERVERSERVICE_19990_FALSE_TRUE -s ~/src/real_good_robot/simulation/simulation.ttt
Tab 8: ~/src/CoppeliaSim_Edu_V4_0_0_Ubuntu18_04/coppeliaSim.sh -gREMOTEAPISERVERSERVICE_19998_FALSE_TRUE -s ~/src/real_good_robot/simulation/simulation.ttt

Tab 9: ~/src/CoppeliaSim_Edu_V4_0_0_Ubuntu18_04/coppeliaSim.sh -gREMOTEAPISERVERSERVICE_19999_FALSE_TRUE -s ~/src/real_good_robot/simulation/simulation.ttt
Tab 10: ~/src/CoppeliaSim_Edu_V4_0_0_Ubuntu18_04/coppeliaSim.sh -gREMOTEAPISERVERSERVICE_20000_FALSE_TRUE -s ~/src/real_good_robot/simulation/simulation.ttt





SIM STACK - SPOT STANDARD Trial rtrial Task Progress - TRIAL REWARD - RANDOM ACTIONS - SORT TRIAL REWARD - REWARD SCHEDULE 0.1, 1, 1 - workstation named spot 2020-05-28
----------------------------------------------------------------------------------------
export CUDA_VISIBLE_DEVICES="0" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 8 --push_rewards --experience_replay --explore_rate_decay --trial_reward --check_z_height --tcp_port 19990 --place --future_reward_discount 0.65 --max_train_actions 20000 --random_actions
RESUME: ± export CUDA_VISIBLE_DEVICES="0" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 8 --push_rewards --experience_replay --explore_rate_decay --trial_reward --check_z_height --tcp_port 19990 --place --future_reward_discount 0.65 --max_train_actions 20000 --random_actions --resume /home/ahundt/src/real_good_robot/logs/2020-05-28-12-09-32_Sim-Stack-SPOT-Trial-Reward-Training
Creating data logging session: /home/ahundt/src/real_good_robot/logs/2020-05-28-12-09-32_Sim-Stack-SPOT-Trial-Reward-Training
Commit: a534735959ec2747c3b134a6d3067135a5c7bd75  release tag:v0.16.0
GPU 0, Tab 0, port 19990, left v-rep window, v-rep tab 7

CANCELLED BECAUSE IT IS NOT THE RUN WE NEED RIGHT NOW - 2020-05-30 - TODO MAYBE RESUME LATER, finished around 7k actions


SIM ROW - SPOT STANDARD Trial rtrial Task Progress - TRIAL REWARD - RANDOM ACTIONS - SORT TRIAL REWARD -  REWARD SCHEDULE 0.1, 1, 1 - workstation named spot 2020-05-28
----------------------------------------------------------------------------------------
export CUDA_VISIBLE_DEVICES="1" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 4 --push_rewards --experience_replay --explore_rate_decay --trial_reward --check_row --tcp_port 19998 --place --future_reward_discount 0.65 --max_train_actions 20000 --random_actions
RESUME: export CUDA_VISIBLE_DEVICES="1" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 4 --push_rewards --experience_replay --explore_rate_decay --trial_reward --check_row --tcp_port 19998 --place --future_reward_discount 0.65 --max_train_actions 20000 --random_actions --resume /home/ahundt/src/real_good_robot/logs/2020-05-28-12-10-18_Sim-Rows-SPOT-Trial-Reward-Training
Creating data logging session: /home/ahundt/src/real_good_robot/logs/2020-05-28-12-10-18_Sim-Rows-SPOT-Trial-Reward-Training
Commit: a534735959ec2747c3b134a6d3067135a5c7bd75  release tag:v0.16.0
GPU 1, Tab 1, port 19998, center left v-rep window, v-rep tab 8


CANCELLED BECAUSE IT IS NOT THE RUN WE NEED RIGHT NOW - 2020-05-30 - TODO MAYBE RESUME LATER, finished around 7k actions - Resumed june 2020
RESUME: GPU 3, Tab 3, port 20000, right v-rep window, v-rep tab 10
RESUME Commit: 36a0c6a8cfd6c0d8a087f0b647814575054faedd release tag: v0.16.3
RESUME: export CUDA_VISIBLE_DEVICES="3" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 4 --push_rewards --experience_replay --explore_rate_decay --trial_reward --check_row --tcp_port 20000 --place --future_reward_discount 0.65 --max_train_actions 20000 --random_actions --resume /home/ahundt/src/real_good_robot/logs/2020-05-28-12-10-18_Sim-Rows-SPOT-Trial-Reward-Training

    > '/home/ahundt/src/real_good_robot/logs/2020-05-28-12-10-18_Sim-Rows-SPOT-Trial-Reward-Training/2020-06-11-00-40-54_Sim-Rows-SPOT-Trial-Reward-Testing/best_stats.json'
    > {"action_efficiency_best_index": 1779, "action_efficiency_best_value": 0.29375351716375914, "grasp_success_rate_best_index": 1778, "grasp_success_rate_best_value": 0.33109619686800895, "place_success_rate_best_index": null, "place_success_rate_best_value": -Infinity, "trial_success_rate_best_index": 1777, "trial_success_rate_best_value": 0.74}
    >
    > place success rate log value: 8.744292237442922167e-01 
    > Manually edited json with place success rate :
    > '/home/ahundt/src/real_good_robot/logs/2020-05-28-12-10-18_Sim-Rows-SPOT-Trial-Reward-Training/2020-06-11-00-40-54_Sim-Rows-SPOT-Trial-Reward-Testing/best_stats.json'
    > {"action_efficiency_best_index": 1779, "action_efficiency_best_value": 0.29375351716375914, "grasp_success_rate_best_index": 1778, "grasp_success_rate_best_value": 0.33109619686800895, "place_success_rate_best_index": null, "place_success_rate_best_value": 0.874, "trial_success_rate_best_index": 1777, "trial_success_rate_best_value": 0.74}




SIM STACK - Trial Situation Removal - RANDOM ACTIONS - SORT TRIAL REWARD - REWARD SCHEDULE 0.1, 1, 1 - workstation named spot 2020-05-28
----------------------------------------------------------------------------------------
export CUDA_VISIBLE_DEVICES="2" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 8 --push_rewards --experience_replay --explore_rate_decay --trial_reward --check_z_height --tcp_port 19999 --place --future_reward_discount 0.65 --max_train_actions 20000 --random_actions --no_height_reward
RESUME: export CUDA_VISIBLE_DEVICES="2" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 8 --push_rewards --experience_replay --explore_rate_decay --trial_reward --check_z_height --tcp_port 19999 --place --future_reward_discount 0.65 --max_train_actions 20000 --random_actions --no_height_reward --resume /home/ahundt/src/real_good_robot/logs/2020-05-28-12-11-00_Sim-Stack-SPOT-Trial-Reward-Training
Creating data logging session: /home/ahundt/src/real_good_robot/logs/2020-05-28-12-11-00_Sim-Stack-SPOT-Trial-Reward-Training
Commit: a534735959ec2747c3b134a6d3067135a5c7bd75  release tag:v0.16.0
GPU 2, Tab 2, port 19999, left v-rep window, v-rep tab 9


CANCELLED BECAUSE IT IS NOT THE RUN WE NEED RIGHT NOW - 2020-05-30 - TODO MAYBE RESUME LATER, finished around 7k actions


SIM ROW - Trial Situation Removal - RANDOM ACTIONS - SORT TRIAL REWARD -  REWARD SCHEDULE 0.1, 1, 1 - workstation named spot 2020-05-28
----------------------------------------------------------------------------------------
export CUDA_VISIBLE_DEVICES="3" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 4 --push_rewards --experience_replay --explore_rate_decay --trial_reward --check_row --tcp_port 20000 --place --future_reward_discount 0.65 --max_train_actions 20000 --random_actions --no_height_reward
RESUME: ± export CUDA_VISIBLE_DEVICES="3" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 4 --push_rewards --experience_replay --explore_rate_decay --trial_reward --check_row --tcp_port 20000 --place --future_reward_discount 0.65 --max_train_actions 20000 --random_actions --no_height_reward --resume /home/ahundt/src/real_good_robot/logs/2020-05-28-12-11-38_Sim-Rows-SPOT-Trial-Reward-Training
Creating data logging session: /home/ahundt/src/real_good_robot/logs/2020-05-28-12-11-38_Sim-Rows-SPOT-Trial-Reward-Training
Commit: a534735959ec2747c3b134a6d3067135a5c7bd75  release tag:v0.16.0
GPU 3, Tab 3, port 19999, center left v-rep window, v-rep tab 10


CANCELLED BECAUSE IT IS NOT THE RUN WE NEED RIGHT NOW - 2020-05-30 - TODO MAYBE RESUME LATER, finished around 7k actions











SIM ROW - Trial Situation Removal - RANDOM ACTIONS - SORT TRIAL REWARD -  REWARD SCHEDULE 0.1, 1, 1 - workstation named spot 2020-05-30
----------------------------------------------------------------------------------------
export CUDA_VISIBLE_DEVICES="3" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 4 --push_rewards --experience_replay --explore_rate_decay --check_row --tcp_port 20000 --place --future_reward_discount 0.65 --max_train_actions 20000 --random_actions --no_height_reward
Creating data logging session: /home/ahundt/src/real_good_robot/logs/2020-05-30-13-12-47_Sim-Rows-SPOT-Trial-Reward-Training
Commit: 12d9481717486342dbfcaff191ddb1428f102406  release tag:v0.16.1
GPU 3, Tab 3, port 19999, center left v-rep window, v-rep tab 10


CANCELLED BECAUSE IT IS NOT THE RUN WE NEED RIGHT NOW - 2020-05-30 - TODO MAYBE RESUME LATER, finished around 1k actions





Pass 1 - Ablation of instant reward shcedules
============================================================================================================================











SIM STACK - Task Progress aka progress only - RANDOM ACTIONS - REWARD SCHEDULE 0.1, 1, 1 - workstation named spot 2020-05-30
----------------------------------------------------------------------------------------
export CUDA_VISIBLE_DEVICES="0" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 8 --push_rewards --experience_replay --explore_rate_decay --check_z_height --tcp_port 19990 --place --future_reward_discount 0.65 --max_train_actions 20000 --random_actions
Creating data logging session: /home/ahundt/src/real_good_robot/logs/2020-05-30-13-09-38_Sim-Stack-Two-Step-Reward-Training
Commit: 12d9481717486342dbfcaff191ddb1428f102406  release tag:v0.16.1
GPU 0, Tab 0, port 19990, left v-rep window, v-rep tab 7



    > Trial logging complete: 101 --------------------------------------------------------------
    > Running two step backprop()
    > Primitive confidence scores: 3.220978 (push), 7.850247 (grasp), 7.190622 (place)
    > Action: grasp at (4, 7, 152)
    > Training loss: 0.672980
    > Executing: grasp at (-0.420000, -0.210000, 0.001003) orientation: 1.570796
    > gripper position: 0.0304451584815979
    > gripper position: 0.026506200432777405
    > gripper position: 0.0013817846775054932
    > gripper position: -0.022582605481147766
    > gripper position: -0.04284219443798065
    > Grasp successful: False
    > prev_height: 0.0 max_z: 0.05112840983826451 goal_success: True needed to reset: False max_workspace_height: -0.02 <<<<<<<<<<<
    > prev_height: 1.0 max_z: 1.0225681967652902 goal_success: False needed to reset: False max_workspace_height: 0.6 <<<<<<<<<<<
    > check_stack() stack_height: 1.0225681967652902 stack matches current goal: False partial_stack_success: False Does the code think a reset
    > is needed: False
    > STACK:  trial: 101 actions/partial: 3.662721893491124  actions/full stack: 12.505050505050505 (lower is better)  Grasp Count: 663, grasp success rate: 0.8310708898944194 place_on_stack_rate: 0.6134301270417423 place_attempts: 551  partial_stack_successes: 338  stack_successes: 99 trial_success_rate: 0.9801980198019802 stack goal: None current_height: 1.0225681967652902
    > trial_complete_indices: [  13.   19.   32.   44.   68.   76.   86.  102.  112.  118.  125.  133.
    >   139.  145.  180.  186.  192.  198.  205.  213.  221.  232.  240.  293.
    >   299.  309.  317.  323.  333.  349.  354.  365.  376.  380.  393.  403.
    >   420.  456.  476.  492.  496.  504.  515.  521.  531.  537.  543.  551.
    >   560.  575.  585.  591.  600.  610.  620.  631.  639.  645.  652.  658.
    >   672.  704.  711.  717.  721.  729.  746.  758.  764.  770.  778.  784.
    >   790.  796.  806.  812.  855.  861.  897.  905.  915.  919.  928.  962.
    >   968.  972.  979.  987.  993.  997. 1007. 1013. 1031. 1043. 1149. 1160.
    >  1168. 1178. 1195. 1231. 1237.]
    > Max trial success rate: 0.98, at action iteration: 1234. (total of 1236 actions, max excludes first 1234 actions)
    > Max grasp success rate: 0.8335854765506808, at action iteration: 1235. (total of 1236 actions, max excludes first 1234 actions)
    > Max place success rate: 0.7426086956521739, at action iteration: 1236. (total of 1237 actions, max excludes first 1234 actions)
    > Max action efficiency: 0.5153970826580226, at action iteration: 1236. (total of 1237 actions, max excludes first 1234 actions)
    > saving plot: 2020-06-03-03-08-00_Sim-Stack-Two-Step-Reward-Testing-Sim-Stack-Two-Step-Reward-Testing_success_plot.png
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-06-03-03-08-00_Sim-Stack-Two-Step-Reward-Testing/data/best_stats.json
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-06-03-03-08-00_Sim-Stack-Two-Step-Reward-Testing/best_stats.json
    > Random Testing Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-05-30-13-09-38_Sim-Stack-Two-Step-Reward-Training/2020-06-03-03-08-00_Sim-Stack-Two-Step-Reward-Testing
    > Random Testing results:
    >  {'trial_success_rate_best_value': 0.98, 'trial_success_rate_best_index': 1234, 'grasp_success_rate_best_value': 0.8335854765506808, 'grasp_success_rate_best_index': 1235, 'place_success_rate_best_value': 0.7426086956521739, 'place_success_rate_best_index': 1236, 'action_efficiency_best_value': 0.5153970826580226, 'action_efficiency_best_index': 1236}
    > Training Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-05-30-13-09-38_Sim-Stack-Two-Step-Reward-Training
    > Training results:
    >  {'trial_success_rate_best_value': 0.8103448275862069, 'trial_success_rate_best_index': 19569, 'grasp_success_rate_best_value': 0.9494163424124513, 'grasp_success_rate_best_index': 12019, 'place_success_rate_best_value': 0.8312236286919831, 'place_success_rate_best_index': 17156, 'action_efficiency_best_value': 0.6, 'action_efficiency_best_index': 19471}



SIM ROW - Task Progress aka progress only - REWARD SCHEDULE 0.1, 1, 1 - workstation named spot 2020-05-30
----------------------------------------------------------------------------------------
export CUDA_VISIBLE_DEVICES="1" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 4 --push_rewards --experience_replay --explore_rate_decay --check_row --tcp_port 19998 --place --future_reward_discount 0.65 --max_train_actions 20000 --random_actions
Creating data logging session: /home/ahundt/src/real_good_robot/logs/2020-05-30-13-10-52_Sim-Rows-Two-Step-Reward-Training
Commit: 12d9481717486342dbfcaff191ddb1428f102406  release tag:v0.16.1
GPU 1, Tab 1, port 19998, center left v-rep window, v-rep tab 8



    > Trial logging complete: 101 --------------------------------------------------------------
    > Running two step backprop()
    > Primitive confidence scores: 5.558454 (push), 8.079895 (grasp), 9.956761 (place)
    > Action: grasp at (4, 183, 167)
    > Training loss: 0.173360
    > Executing: grasp at (-0.390000, 0.142000, 0.001004) orientation: 1.570796
    > gripper position: 0.030987784266471863
    > gripper position: 0.02650594152510166
    > gripper position: 0.0014807581901550293
    > gripper position: -0.023117437958717346
    > gripper position: -0.042321473360061646
    > Grasp successful: False
    > prev_height: 0.0 max_z: 0.05110803083189876 goal_success: True needed to reset: False max_workspace_height: -0.02 <<<<<<<<<<<
    > check_row: True | row_size: 2 | blocks: ['blue' 'red']
    > check_stack() stack_height: 2 stack matches current goal: True partial_stack_success: True Does the code think a reset is needed: False
    > STACK:  trial: 101 actions/partial: 6.386363636363637  actions/full stack: 11.46938775510204 (lower is better)  Grasp Count: 618, grasp success rate: 0.8220064724919094 place_on_stack_rate: 0.34782608695652173 place_attempts: 506  partial_stack_successes: 176  stack_successes: 98 trial_success_rate: 0.9702970297029703 stack goal: [3 2] current_height: 2
    > trial_complete_indices: [   4.    8.   12.   18.   23.   28.   32.   36.   40.   44.   50.   54.
    > 58.   62.   66.   68.   72.   76.   80.   84.  485.  491.  499.  503.
    > 509.  511.  517.  521.  525.  708.  712.  714.  720.  728.  730.  736.
    > 740.  742.  749.  753.  758.  770.  776.  778.  786.  790.  794.  801.
    > 805.  809.  811.  813.  815.  819.  828.  832.  836.  840.  845.  849.
    > 861.  865.  869.  872.  878.  882.  886.  888.  890.  894.  896.  900.
    > 904.  950.  955.  957.  963.  968.  976.  980.  982.  988.  991.  993.
    > 999. 1044. 1053. 1057. 1064. 1068. 1074. 1078. 1092. 1096. 1100. 1104.
    > 1106. 1110. 1114. 1118. 1123.]
    > Max trial success rate: 0.97, at action iteration: 1120. (total of 1122 actions, max excludes first 1120 actions)
    > Max grasp success rate: 0.823051948051948, at action iteration: 1120. (total of 1122 actions, max excludes first 1120 actions)
    > Max place success rate: 0.8950495049504951, at action iteration: 1120. (total of 1123 actions, max excludes first 1120 actions)
    > Max action efficiency: 0.5303571428571429, at action iteration: 1122. (total of 1123 actions, max excludes first 1120 actions)
    > saving plot: 2020-06-03-07-00-00_Sim-Rows-Two-Step-Reward-Testing-Sim-Rows-Two-Step-Reward-Testing_success_plot.png
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-06-03-07-00-00_Sim-Rows-Two-Step-Reward-Testing/data/best_stats.json
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-06-03-07-00-00_Sim-Rows-Two-Step-Reward-Testing/best_stats.json
    > Random Testing Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-05-30-13-10-52_Sim-Rows-Two-Step-Reward-Training/2020-06-03-07-00-00_Sim-Rows-Two-Step-Reward-Testing
    > Random Testing results:
    > {'trial_success_rate_best_value': 0.97, 'trial_success_rate_best_index': 1120, 'grasp_success_rate_best_value': 0.823051948051948, 'grasp_success_rate_best_index': 1120, 'place_success_rate_best_value': 0.8950495049504951, 'place_success_rate_best_index': 1120, 'action_efficiency_best_value': 0.5303571428571429, 'action_efficiency_best_index': 1122}
    > Training Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-05-30-13-10-52_Sim-Rows-Two-Step-Reward-Training
    > Training results:
    > {'action_efficiency_best_index': 18908, 'action_efficiency_best_value': 1.248, 'grasp_success_rate_best_index': 17217, 'grasp_success_rate_best_value': 0.8145454545454546, 'place_success_rate_best_index': 13436, 'place_success_rate_best_value': 0.9345794392523364, 'trial_success_rate_best_index': 18572, 'trial_success_rate_best_value': 0.768}





SIM STACK - Basic Situation Removal - RANDOM ACTIONS - SORT TRIAL REWARD - REWARD SCHEDULE 0.1, 1, 1 - workstation named spot 2020-05-30
----------------------------------------------------------------------------------------
export CUDA_VISIBLE_DEVICES="2" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 8 --push_rewards --experience_replay --explore_rate_decay --check_z_height --tcp_port 19999 --place --future_reward_discount 0.65 --max_train_actions 20000 --random_actions --no_height_reward
Creating data logging session: /home/ahundt/src/real_good_robot/logs/2020-05-30-13-11-57_Sim-Stack-Two-Step-Reward-Training
Commit: 12d9481717486342dbfcaff191ddb1428f102406  release tag:v0.16.1
GPU 2, Tab 2, port 19999, left v-rep window, v-rep tab 9

    > '/home/ahundt/src/real_good_robot/logs/2020-05-30-13-11-57_Sim-Stack-Two-Step-Reward-Training/2020-06-02-19-24-53_Sim-Stack-Two-Step-Reward-Testing'
    > {"action_efficiency_best_index": 7161, "action_efficiency_best_value": 0.07710574102528286, "grasp_success_rate_best_index": 7159, "grasp_success_rate_best_value": 0.8780807551127425, "place_success_rate_best_index": 7159, "place_success_rate_best_value": 0.6434548714883442, "trial_success_rate_best_index": 7159, "trial_success_rate_best_value": 0.9}


SIM ROW - Basic Situation Removal - RANDOM ACTIONS - SORT TRIAL REWARD -  REWARD SCHEDULE 0.1, 1, 1 - workstation named spot 2020-05-30
----------------------------------------------------------------------------------------
export CUDA_VISIBLE_DEVICES="3" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 4 --push_rewards --experience_replay --explore_rate_decay --check_row --tcp_port 20000 --place --future_reward_discount 0.65 --max_train_actions 20000 --random_actions --no_height_reward
Creating data logging session: /home/ahundt/src/real_good_robot/logs/2020-05-30-17-46-01_Sim-Rows-Two-Step-Reward-Training
Commit: 12d9481717486342dbfcaff191ddb1428f102406  release tag:v0.16.1
GPU 3, Tab 3, port 20000, center left v-rep window, v-rep tab 10


    > Complete first test run trial success rate best value model:
    > {"action_efficiency_best_index": 2092, "action_efficiency_best_value": 0.28995215311004785, "grasp_success_rate_best_index": 2090, "grasp_success_rate_best_value": 0.8680926916221033, "place_success_rate_best_index": 2090, "place_success_rate_best_value": 0.5927835051546392, "trial_success_rate_best_index": 2090, "trial_success_rate_best_value": 0.94}
    > Max trial success rate: 0.94, at action iteration: 2090. (total of 2092 actions, max excludes first 2090 actions)                         
    > Max grasp success rate: 0.8680926916221033, at action iteration: 2090. (total of 2092 actions, max excludes first 2090 actions)           Max place success rate: 0.5927835051546392, at action iteration: 2090. (total of 2091 actions, max excludes first 2090 actions)           
    > Max action efficiency: 0.28995215311004785, at action iteration: 2092. (total of 2093 actions, max excludes first 2090 actions)           
    > saving plot: 2020-06-03-06-28-31_Sim-Rows-Two-Step-Reward-Testing-Sim-Rows-Two-Step-Reward-Testing_success_plot.png                       saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-06-03-06-28-31_Sim-Rows-Two-Step-Reward-Testing/data/best_stats.json     
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-06-03-06-28-31_Sim-Rows-Two-Step-Reward-Testing/best_stats.json          
    > Trial logging complete: 101 --------------------------------------------------------------



    > *Partially* complete second test run, best action efficiency model:
    > -------------------------------------
    > Max trial success rate: 0.9710144927536232, at action iteration: 1741. (total of 1743 actions, max excludes first 1741 actions)
    > Max grasp success rate: 0.9186176142697882, at action iteration: 1741. (total of 1743 actions, max excludes first 1741 actions)           
    > Max place success rate: 0.6415552855407047, at action iteration: 1741. (total of 1742 actions, max excludes first 1741 actions)
    > Max action efficiency: 0.24813325674899483, at action iteration: 1743. (total of 1744 actions, max excludes first 1741 actions)
    > saving plot: 2020-06-03-15-46-00_Sim-Rows-Two-Step-Reward-Testing-Sim-Rows-Two-Step-Reward-Testing_success_plot.png                       
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-06-03-15-46-00_Sim-Rows-Two-Step-Reward-Testing/data/best_stats.json     saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-06-03-15-46-00_Sim-Rows-Two-Step-Reward-Testing/best_stats.json          
    > Trial logging complete: 70 -------------------------------------------------------------- 











Pass 2 - SPOT-Q TASK PROGRESS MASKED
===========================================================================================================================







SIM STACK - Task Progress SPOT-Q MASKED - RANDOM ACTIONS - REWARD SCHEDULE 0.1, 1, 1 - workstation named spot 2020-06-03
----------------------------------------------------------------------------------------
export CUDA_VISIBLE_DEVICES="0" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 8 --push_rewards --experience_replay --explore_rate_decay --check_z_height --tcp_port 19990 --place --future_reward_discount 0.65 --max_train_actions 20000 --random_actions --common_sense
Creating data logging session: /home/ahundt/src/real_good_robot/logs/2020-06-03-11-44-02_Sim-Stack-Two-Step-Reward-Masked-Training
Commit: 12d9481717486342dbfcaff191ddb1428f102406  release tag:v0.16.1
GPU 0, Tab 0, port 19990, left v-rep window, v-rep tab 7

    > Trial logging complete: 101 --------------------------------------------------------------
    > prev_height: 0.0 max_z: 0.05115434739934034 goal_success: True needed to reset: False max_workspace_height: -0.02 <<<<<<<<<<<
    > prev_height: 1.0 max_z: 1.0230869479868068 goal_success: False needed to reset: False max_workspace_height: 0.6 <<<<<<<<<<<
    > check_stack() stack_height: 1.0230869479868068 stack matches current goal: False partial_stack_success: False Does the code think a reset
    > is needed: False
    > STACK:  trial: 101 actions/partial: 3.8494318181818183  actions/full stack: 13.415841584158416 (lower is better)  Grasp Count: 768, grasp
    > success rate: 0.7552083333333334 place_on_stack_rate: 0.6068965517241379 place_attempts: 580  partial_stack_successes: 352  stack_successes: 101 trial_success_rate: 1.0 stack goal: None current_height: 1.0230869479868068
    > trial_complete_indices: [   7.   20.   30.   36.   45.   74.   84.   99.  118.  138.  167.  177.
    >   189.  213.  225.  249.  255.  269.  275.  283.  290.  305.  323.  327.
    >   341.  351.  360.  391.  403.  420.  446.  457.  472.  481.  505.  534.
    >   543.  553.  562.  573.  592.  600.  606.  620.  626.  658.  664.  674.
    >   680.  689.  697.  705.  709.  726.  737.  745.  760.  764.  770.  780.
    >   791.  827.  850.  862.  878.  897.  905.  917.  930.  958.  971.  982.
    >  1022. 1028. 1034. 1047. 1062. 1069. 1078. 1084. 1102. 1109. 1114. 1133.
    >  1145. 1165. 1173. 1184. 1221. 1233. 1241. 1252. 1275. 1282. 1290. 1296.
    >  1312. 1319. 1333. 1342. 1354.]
    > Max trial success rate: 1.0, at action iteration: 1351. (total of 1353 actions, max excludes first 1351 actions)
    > Max grasp success rate: 0.7558746736292428, at action iteration: 1351. (total of 1353 actions, max excludes first 1351 actions)
    > Max place success rate: 0.757679180887372, at action iteration: 1351. (total of 1354 actions, max excludes first 1351 actions)
    > Max action efficiency: 0.44855662472242785, at action iteration: 1353. (total of 1354 actions, max excludes first 1351 actions)
    > saving plot: 2020-06-07-06-26-25_Sim-Stack-Two-Step-Reward-Masked-Testing-Sim-Stack-Two-Step-Reward-Masked-Testing_success_plot.png
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-06-07-06-26-25_Sim-Stack-Two-Step-Reward-Masked-Testing/data/best_stats.json
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-06-07-06-26-25_Sim-Stack-Two-Step-Reward-Masked-Testing/best_stats.json
    > Random Testing Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-03-11-44-02_Sim-Stack-Two-Step-Reward-Masked-Training/2020-06-07-06-26-25_Sim-Stack-Two-Step-Reward-Masked-Testing
    > Random Testing results:
    >  {'trial_success_rate_best_value': 1.0, 'trial_success_rate_best_index': 1351, 'grasp_success_rate_best_value': 0.7558746736292428, 'grasp_success_rate_best_index': 1351, 'place_success_rate_best_value': 0.757679180887372, 'place_success_rate_best_index': 1351, 'action_efficiency_best_value': 0.44855662472242785, 'action_efficiency_best_index': 1353}
    > Training Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-03-11-44-02_Sim-Stack-Two-Step-Reward-Masked-Training
    > Training results:
    >  {'trial_success_rate_best_value': 0.7931034482758621, 'trial_success_rate_best_index': 12797, 'grasp_success_rate_best_value': 0.937984496124031, 'grasp_success_rate_best_index': 13126, 'place_success_rate_best_value': 0.8201754385964912, 'place_success_rate_best_index': 19959, 'action_efficiency_best_value': 0.576, 'action_efficiency_best_index': 12886}




SIM ROW - Task Progress SPOT-Q MASKED - REWARD SCHEDULE 0.1, 1, 1 - workstation named spot 2020-06-03
----------------------------------------------------------------------------------------
export CUDA_VISIBLE_DEVICES="1" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 4 --push_rewards --experience_replay --explore_rate_decay --check_row --tcp_port 19998 --place --future_reward_discount 0.65 --max_train_actions 20000 --random_actions --common_sense
Creating data logging session: /home/ahundt/src/real_good_robot/logs/2020-06-03-12-05-28_Sim-Rows-Two-Step-Reward-Masked-Training
Commit: 12d9481717486342dbfcaff191ddb1428f102406  release tag:v0.16.1
GPU 1, Tab 1, port 19998, center left v-rep window, v-rep tab 8


    > Trial logging complete: 101 --------------------------------------------------------------
    > prev_height: 0.0 max_z: 0.05113576211473993 goal_success: True needed to reset: False max_workspace_height: -0.02 <<<<<<<<<<<
    > check_row: True | row_size: 2 | blocks: ['blue' 'green']
    > check_stack() stack_height: 2 stack matches current goal: False partial_stack_success: False Does the code think a reset is needed: True
    > main.py check_stack() DETECTED PROGRESS REVERSAL, mismatch between the goal height: 3 and current workspace stack height: 2
    > STACK:  trial: 101 actions/partial: 3.1473214285714284  actions/full stack: 7.05 (lower is better)  Grasp Count: 372, grasp success rate:
    > 0.8978494623655914 place_on_stack_rate: 0.6726726726726727 place_attempts: 333  partial_stack_successes: 224  stack_successes: 100 trial_success_rate: 0.9900990099009901 stack goal: [3 2 0 1] current_height: 2
    > trial_complete_indices: [  2.   8.  12.  23.  27.  31.  35.  39.  50.  58.  60.  66.  75.  86.
    >   88.  94. 103. 109. 112. 116. 122. 130. 136. 140. 146. 152. 172. 176.
    >  183. 189. 193. 200. 203. 212. 219. 223. 227. 233. 239. 251. 260. 269.
    >  273. 279. 287. 293. 297. 307. 313. 319. 328. 332. 338. 342. 346. 350.
    >  352. 354. 358. 360. 362. 367. 375. 381. 408. 412. 415. 419. 423. 435.
    >  441. 445. 449. 451. 453. 457. 461. 467. 475. 482. 491. 495. 503. 511.
    >  515. 522. 524. 535. 541. 545. 551. 557. 561. 563. 567. 576. 580. 686.
    >  693. 699. 704.]
    > Max trial success rate: 0.99, at action iteration: 701. (total of 703 actions, max excludes first 701 actions)
    > Max grasp success rate: 0.9, at action iteration: 701. (total of 703 actions, max excludes first 701 actions)
    > Max place success rate: 0.7921686746987951, at action iteration: 701. (total of 704 actions, max excludes first 701 actions)
    > Max action efficiency: 0.8473609129814551, at action iteration: 701. (total of 704 actions, max excludes first 701 actions)
    > saving plot: 2020-06-07-00-35-36_Sim-Rows-Two-Step-Reward-Masked-Testing-Sim-Rows-Two-Step-Reward-Masked-Testing_success_plot.png
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-06-07-00-35-36_Sim-Rows-Two-Step-Reward-Masked-Testing/data/best_stats.json
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-06-07-00-35-36_Sim-Rows-Two-Step-Reward-Masked-Testing/best_stats.json
    > Random Testing Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-03-12-05-28_Sim-Rows-Two-Step-Reward-Masked-Training/2020-06-06-21-34-07_Sim-Rows-Two-Step-Reward-Masked-Testing
    > Random Testing results:
    >  {'trial_success_rate_best_value': 1.0, 'trial_success_rate_best_index': 667, 'grasp_success_rate_best_value': 0.850415512465374, 'grasp_success_rate_best_index': 667, 'place_success_rate_best_value': 0.7752442996742671, 'place_success_rate_best_index': 667, 'action_efficiency_best_value': 0.9265367316341829, 'action_efficiency_best_index': 667}
    > Training Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-03-12-05-28_Sim-Rows-Two-Step-Reward-Masked-Training
    > Training results:
    >  {'trial_success_rate_best_value': 0.7475728155339806, 'trial_success_rate_best_index': 18139, 'grasp_success_rate_best_value': 0.8550185873605948, 'grasp_success_rate_best_index': 18207, 'place_success_rate_best_value': 0.8486238532110092, 'place_success_rate_best_index': 19937, 'action_efficiency_best_value': 1.224, 'action_efficiency_best_index': 19986}






SIM STACK - Task Progress SPOT-Q MASKED - RANDOM ACTIONS - REWARD SCHEDULE 0.1, 1, 1 - workstation named spot 2020-06-03
----------------------------------------------------------------------------------------
export CUDA_VISIBLE_DEVICES="2" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 8 --push_rewards --experience_replay --explore_rate_decay --check_z_height --tcp_port 19999 --place --future_reward_discount 0.65 --max_train_actions 20000 --random_actions --common_sense
Creating data logging session: /home/ahundt/src/real_good_robot/logs/2020-06-04-11-18-49_Sim-Stack-Two-Step-Reward-Masked-Training
Commit: 12d9481717486342dbfcaff191ddb1428f102406  release tag:v0.16.1
GPU 2, Tab 2, port 19999, right center v-rep window, v-rep tab 9

    > note that we ran one extra test with place success rate, since it appears there was a glitch in the action efficiency records. This is a simulator bug which may worsen final results.
    > '/home/ahundt/src/real_good_robot/logs/2020-06-04-11-18-49_Sim-Stack-Two-Step-Reward-Masked-Training/2020-06-07-19-54-35_Sim-Stack-Two-Step-Reward-Masked-Testing'
    > {"action_efficiency_best_index": 2284, "action_efficiency_best_value": 0.25241016652059595, "grasp_success_rate_best_index": 2282, "grasp_success_rate_best_value": 0.7245283018867924, "place_success_rate_best_index": 2282, "place_success_rate_best_value": 0.6659707724425887, "trial_success_rate_best_index": 2282, "trial_success_rate_best_value": 0.94}
    > Trial logging complete: 101 --------------------------------------------------------------
    > Running two step backprop()
    > Primitive confidence scores: 3.534616 (push), 7.419805 (grasp), 7.226346 (place)
    > Action: grasp at (0, 168, 167)
    > Training loss: 0.130998
    > Executing: grasp at (-0.390000, 0.112000, 0.051003) orientation: 0.000000
    > gripper position: 0.03104463219642639
    > gripper position: 0.026297718286514282
    > gripper position: 0.0010769963264465332
    > gripper position: -0.022954285144805908
    > gripper position: -0.04172489047050476
    > Grasp successful: False
    > prev_height: 0.0 max_z: 0.05112415348966427 goal_success: True needed to reset: False max_workspace_height: -0.02 <<<<<<<<<<<
    > prev_height: 1.0 max_z: 1.0224830697932854 goal_success: False needed to reset: False max_workspace_height: 0.6 <<<<<<<<<<<
    > check_stack() stack_height: 1.0224830697932854 stack matches current goal: False partial_stack_success: False Does the code think a reset is needed: False
    > STACK:  trial: 101 actions/partial: 5.6658536585365855  actions/full stack: 23.948453608247423 (lower is better)  Grasp Count: 1344, grasp success rate: 0.7313988095238095 place_on_stack_rate: 0.4187946884576098 place_attempts: 979  partial_stack_successes: 410  stack_successes: 97 trial_success_rate: 0.9603960396039604 stack goal: None current_height: 1.0224830697932854
    > trial_complete_indices: [   9.   17.   37.   64.   79.   90.  159.  220.  224.  232.  260.  271.
    > 279.  290.  304.  314.  393.  425.  479.  483.  502.  508.  518.  533.
    > 551.  582.  598.  604.  617.  632.  636.  648.  660.  692.  700.  719.
    > 743.  767.  794.  809.  840.  850.  996. 1008. 1016. 1045. 1071. 1087.
    > 1105. 1116. 1141. 1160. 1207. 1287. 1306. 1321. 1330. 1339. 1359. 1403.
    > 1417. 1431. 1438. 1449. 1459. 1519. 1544. 1550. 1593. 1605. 1611. 1647.
    > 1664. 1683. 1692. 1706. 1720. 1767. 1797. 1934. 1958. 2008. 2031. 2048.
    > 2070. 2079. 2099. 2111. 2121. 2131. 2137. 2146. 2163. 2203. 2219. 2229.
    > 2241. 2246. 2254. 2305. 2322.]
    > Max trial success rate: 0.96, at action iteration: 2319. (total of 2321 actions, max excludes first 2319 actions)
    > Max grasp success rate: 0.732488822652757, at action iteration: 2320. (total of 2321 actions, max excludes first 2319 actions)
    > Max place success rate: 0.693564862104188, at action iteration: 2321. (total of 2322 actions, max excludes first 2319 actions)
    > Max action efficiency: 0.25097024579560157, at action iteration: 2321. (total of 2322 actions, max excludes first 2319 actions)
    > saving plot: 2020-06-08-05-43-46_Sim-Stack-Two-Step-Reward-Masked-Testing-Sim-Stack-Two-Step-Reward-Masked-Testing_success_plot.png
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-06-08-05-43-46_Sim-Stack-Two-Step-Reward-Masked-Testing/data/best_stats.json
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-06-08-05-43-46_Sim-Stack-Two-Step-Reward-Masked-Testing/best_stats.json
    > Random Testing Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-04-11-18-49_Sim-Stack-Two-Step-Reward-Masked-Training/2020-06-08-05-43-46_Sim-Stack-Two-Step-Reward-Masked-Testing
    > Random Testing results:
    > {'trial_success_rate_best_value': 0.96, 'trial_success_rate_best_index': 2319, 'grasp_success_rate_best_value': 0.732488822652757, 'grasp_success_rate_best_index': 2320, 'place_success_rate_best_value': 0.693564862104188, 'place_success_rate_best_index': 2321, 'action_efficiency_best_value': 0.25097024579560157, 'action_efficiency_best_index': 2321}
    > Training Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-04-11-18-49_Sim-Stack-Two-Step-Reward-Masked-Training
    > Training results:
    > {'trial_success_rate_best_value': 0.8125, 'trial_success_rate_best_index': 10322, 'grasp_success_rate_best_value': 0.8905660377358491, 'grasp_success_rate_best_index': 10252, 'place_success_rate_best_value': 0.8028169014084507, 'place_success_rate_best_index': 4893, 'action_efficiency_best_value': 0.792, 'action_efficiency_best_index': 12478}



SIM ROW - Task Progress SPOT-Q MASKED - REWARD SCHEDULE 0.1, 1, 1 - workstation named spot 2020-06-03
----------------------------------------------------------------------------------------
export CUDA_VISIBLE_DEVICES="3" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 4 --push_rewards --experience_replay --explore_rate_decay --check_row --tcp_port 20000 --place --future_reward_discount 0.65 --max_train_actions 20000 --random_actions --common_sense
Creating data logging session: /home/ahundt/src/real_good_robot/logs/2020-06-03-23-18-31_Sim-Rows-Two-Step-Reward-Masked-Training
Commit: 12d9481717486342dbfcaff191ddb1428f102406  release tag:v0.16.1
GPU 3, Tab 3, port 20000, right v-rep window, v-rep tab 10


    > Trial logging complete: 101 --------------------------------------------------------------
    > Grasp successful: False
    > prev_height: 0.0 max_z: 0.051105467279345854 goal_success: True needed to reset: False max_workspace_height: -0.02 <<<<<<<<<<<
    > check_row: True | row_size: 3 | blocks: ['blue' 'green' 'red']
    > check_stack() stack_height: 3 stack matches current goal: True partial_stack_success: True Does the code think a reset is needed: False
    > STACK:  trial: 101 actions/partial: 2.911214953271028  actions/full stack: 6.23 (lower is better)  Grasp Count: 333, grasp success rate: 0.8738738738738738 place_on_stack_rate: 0.7379310344827587 place_attempts: 290  partial_stack_successes: 214  stack_successes: 100 trial_success_rate: 0.9900990099009901 stack goal: [0 2] current_height: 3
    > trial_complete_indices: [  4.   8.  10.  12.  17.  40.  54.  61.  65.  71.  78.  82.  87.  91.
    >   95.  99. 101. 105. 111. 117. 123. 127. 131. 135. 143. 147. 151. 155.
    >  159. 169. 173. 177. 181. 190. 196. 200. 206. 210. 214. 220. 225. 232.
    >  240. 244. 252. 256. 260. 268. 272. 299. 303. 315. 325. 330. 334. 336.
    >  343. 349. 351. 356. 364. 368. 370. 374. 378. 403. 414. 418. 420. 428.
    >  432. 436. 440. 442. 446. 450. 458. 464. 479. 490. 535. 538. 542. 546.
    >  554. 556. 562. 568. 577. 579. 581. 585. 589. 591. 595. 599. 605. 609.
    >  616. 618. 622.]
    > Max trial success rate: 0.98, at action iteration: 619. (total of 621 actions, max excludes first 619 actions)
    > Max grasp success rate: 0.8761329305135952, at action iteration: 619. (total of 621 actions, max excludes first 619 actions)
    > Max place success rate: 0.7612456747404844, at action iteration: 621. (total of 622 actions, max excludes first 619 actions)
    > Max action efficiency: 0.9693053311793215, at action iteration: 621. (total of 622 actions, max excludes first 619 actions)
    > saving plot: 2020-06-07-20-09-08_Sim-Rows-Two-Step-Reward-Masked-Testing-Sim-Rows-Two-Step-Reward-Masked-Testing_success_plot.png
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-06-07-20-09-08_Sim-Rows-Two-Step-Reward-Masked-Testing/data/best_stats.json
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-06-07-20-09-08_Sim-Rows-Two-Step-Reward-Masked-Testing/best_stats.json
    > Random Testing Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-03-23-18-31_Sim-Rows-Two-Step-Reward-Masked-Training/2020-06-07-17-17-16_Sim-Rows-Two-Step-Reward-Masked-Testing
    > Random Testing results:
    >  {'trial_success_rate_best_value': 0.98, 'trial_success_rate_best_index': 614, 'grasp_success_rate_best_value': 0.9190031152647975, 'grasp_success_rate_best_index': 614, 'place_success_rate_best_value': 0.7627118644067796, 'place_success_rate_best_index': 615, 'action_efficiency_best_value': 1.01628664495114, 'action_efficiency_best_index': 616}
    > Training Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-03-23-18-31_Sim-Rows-Two-Step-Reward-Masked-Training
    > Training results:
    >  {'trial_success_rate_best_value': 0.8034188034188035, 'trial_success_rate_best_index': 19062, 'grasp_success_rate_best_value': 0.8321167883211679, 'grasp_success_rate_best_index': 17961, 'place_success_rate_best_value': 0.9090909090909091, 'place_success_rate_best_index': 19959, 'action_efficiency_best_value': 1.26, 'action_efficiency_best_index': 19903}















Pass 3
============================================================



SIM ROW - Basic Situation Removal - RANDOM ACTIONS - SORT TRIAL REWARD -  REWARD SCHEDULE 0.1, 1, 1 - costar 2020-06-07
----------------------------------------------------------------------------------------
export CUDA_VISIBLE_DEVICES="0" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 4 --push_rewards --experience_replay --explore_rate_decay --check_row --tcp_port 19990 --place --future_reward_discount 0.65 --max_train_actions 20000 --random_actions --no_height_reward
Creating data logging session: /home/ahundt/src/real_good_robot/logs/2020-06-07-14-06-58_Sim-Rows-Two-Step-Reward-Training
Commit: 84d192f5e33a8da14b5da245f6649bed9f816884  release tag:v0.16.2
GPU 0, Tab 0, port 19990, left v-rep window, v-rep tab 7

    > Trial logging complete: 101 --------------------------------------------------------------
    > Running two step backprop()
    > Primitive confidence scores: 2.128928 (push), 2.290924 (grasp), 2.470773 (place)
    > Action: grasp at (12, 56, 135)
    > Training loss: 0.090713
    > Executing: grasp at (-0.454000, -0.112000, 0.001002) orientation: 4.712389
    > gripper position: 0.030810609459877014
    > gripper position: 0.026403671130537987
    > gripper position: 0.0011664032936096191
    > gripper position: -0.022915594279766083
    > gripper position: -0.04185757040977478
    > Grasp successful: False
    > prev_height: 0.0 max_z: 0.05111169094181285 goal_success: True needed to reset: False max_workspace_height: -0.02 <<<<<<<<<<<
    > check_row() object_color_sequence length is 0 or 1, so there is nothing to check and it passes automatically
    > check_stack() stack_height: 1 stack matches current goal: True partial_stack_success: False Does the code think a reset is needed: False
    > STACK:  trial: 101 actions/partial: 7.6036363636363635  actions/full stack: 22.010526315789473 (lower is better)  Grasp Count: 1120, grasp success rate: 0.8464285714285714 place_on_stack_rate: 0.291005291005291 place_attempts: 945  partial_stack_successes: 275  stack_successes: 95 trial_success_rate: 0.9405940594059405 stack goal: [0] current_height: 1
    > trial_complete_indices: [   6.    8.   45.   67.  303.  311.  315.  323.  348.  375.  381.  418.
    >   428.  501.  503.  516.  525.  578.  584.  603.  615.  673.  697.  704.
    >   710.  716.  734.  749.  755.  772.  807.  813.  825.  835.  843.  847.
    >   856.  863.  867.  884.  979.  985.  996. 1002. 1008. 1014. 1033. 1037.
    >  1059. 1067. 1071. 1083. 1085. 1095. 1099. 1114. 1131. 1139. 1147. 1151.
    >  1157. 1163. 1175. 1193. 1199. 1214. 1258. 1264. 1289. 1302. 1310. 1312.
    >  1335. 1339. 1387. 1412. 1420. 1478. 1484. 1530. 1538. 1542. 1564. 1588.
    >  1625. 1642. 1650. 1654. 1656. 1704. 1741. 1828. 1841. 1872. 1896. 1954.
    >  2000. 2057. 2063. 2086. 2090.]
    > Max trial success rate: 0.93, at action iteration: 2087. (total of 2089 actions, max excludes first 2087 actions)
    > Max grasp success rate: 0.8470483005366727, at action iteration: 2087. (total of 2089 actions, max excludes first 2087 actions)
    > Max place success rate: 0.6610169491525424, at action iteration: 2087. (total of 2090 actions, max excludes first 2087 actions)
    > Max action efficiency: 0.2788691902252036, at action iteration: 2089. (total of 2090 actions, max excludes first 2087 actions)
    > saving trial success rate: /home/ahundt/src/real_good_robot/logs/2020-06-11-05-20-24_Sim-Rows-Two-Step-Reward-Testing/transitions/trial-success-rate.log.csv
    > saving grasp success rate: /home/ahundt/src/real_good_robot/logs/2020-06-11-05-20-24_Sim-Rows-Two-Step-Reward-Testing/transitions/grasp-success-rate.log.csv
    > saving place success rate: /home/ahundt/src/real_good_robot/logs/2020-06-11-05-20-24_Sim-Rows-Two-Step-Reward-Testing/transitions/place-success-rate.log.csv
    > saving action efficiency: /home/ahundt/src/real_good_robot/logs/2020-06-11-05-20-24_Sim-Rows-Two-Step-Reward-Testing/transitions/action-efficiency.log.csv
    > saving plot: 2020-06-11-05-20-24_Sim-Rows-Two-Step-Reward-Testing-Sim-Rows-Two-Step-Reward-Testing_success_plot.png
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-06-11-05-20-24_Sim-Rows-Two-Step-Reward-Testing/data/best_stats.json
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-06-11-05-20-24_Sim-Rows-Two-Step-Reward-Testing/best_stats.json
    > Random Testing Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-07-14-06-58_Sim-Rows-Two-Step-Reward-Training/2020-06-10-23-16-04_Sim-Rows-Two-Step-Reward-Testing
    > Random Testing results: 
    >  {'trial_success_rate_best_value': 0.98, 'trial_success_rate_best_index': 1456, 'grasp_success_rate_best_value': 0.8350125944584383, 'grasp_success_rate_best_index': 1457, 'place_success_rate_best_value': -inf, 'place_success_rate_best_index': None, 'action_efficiency_best_value': 0.4368131868131868, 'action_efficiency_best_index': 1458}
    > Training Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-07-14-06-58_Sim-Rows-Two-Step-Reward-Training
    > Training results: 
    >  {'trial_success_rate_best_value': 0.5211267605633803, 'trial_success_rate_best_index': 10892, 'grasp_success_rate_best_value': 0.7992831541218638, 'grasp_success_rate_best_index': 16239, 'place_success_rate_best_value': 0.6807511737089202, 'place_success_rate_best_index': 19740, 'action_efficiency_best_value': 0.6, 'action_efficiency_best_index': 19564}


    TODO(ahundt) figure out the source of the place success rate infinite test bug. I looked it up manually in the log and the final value is 6.042296072507552518e-01 (60\%)


Parameter sensitivity experiment - SIM ROW - Task Progress SPOT-Q MASKED - REWARD SCHEDULE 1, 1, 1 - workstation named spot 2020-06-07
----------------------------------------------------------------------------------------
export CUDA_VISIBLE_DEVICES="1" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 4 --push_rewards --experience_replay --explore_rate_decay --check_row --tcp_port 19998 --place --future_reward_discount 0.65 --max_train_actions 20000 --random_actions --common_sense
Creating data logging session: /home/ahundt/src/real_good_robot/logs/2020-06-07-14-07-53_Sim-Rows-Two-Step-Reward-Masked-Training
Commit: 169ee86203c2a360b14fac69bd4b5cef86de3e83  release tag:push_r_weight_1.0_v0
GPU 1, Tab 1, port 19998, center left v-rep window, v-rep tab 8

    > Something really unusual happened here, as trial success wasn't recoreded correctly. Remember this is not a typical run, REWARD SCHEDULE 1, 1, 1 is changed significantly, (push 0.1 -> 1.0). 
    > trial_complete_indices: [  10.   21.   26.   31.   36.   51.   62.   75.   83.   93.  112.  125.
    >   140.  146.  160.  168.  179.  193.  207.  212.  222.  228.  232.  244.
    >   254.  264.  274.  284.  285.  300.  309.  320.  336.  347.  350.  363.
    >   372.  382.  394.  402.  407.  419.  421.  433.  443.  451.  459.  471.
    >   484.  495.  506.  509.  520.  529.  535.  548.  558.  567.  576.  588.
    >   591.  605.  616.  633.  645.  655.  669.  680.  703.  721.  747.  753.
    >   768.  780.  792.  794.  805.  815.  823.  830.  839.  853.  869.  881.
    >   891.  903.  913.  931.  946.  947.  955.  965.  973.  978.  985.  995.
    >  1007. 1028. 1039. 1053.]
    > /home/ahundt/src/real_good_robot/plot.py:136: RuntimeWarning: invalid value encountered in double_scalars
    >   var = np.sqrt(success_rate[i] * (1 - success_rate[i]) / successes.shape[0])
    > Max grasp success rate: 1.0, at action iteration: 1056. (total of 1058 actions, max excludes first 1056 actions)
    > Max place success rate: 0.6666666666666666, at action iteration: 1056. (total of 1059 actions, max excludes first 1056 actions)
    > Max action efficiency: 0.0, at action iteration: 1056. (total of 1059 actions, max excludes first 1056 actions)
    > saving trial success rate: /home/ahundt/src/real_good_robot/logs/2020-06-11-01-28-16_Sim-Rows-Two-Step-Reward-Masked-Testing/transitions/trial-success-rate.log.csv
    > saving grasp success rate: /home/ahundt/src/real_good_robot/logs/2020-06-11-01-28-16_Sim-Rows-Two-Step-Reward-Masked-Testing/transitions/grasp-success-rate.log.csv
    > saving place success rate: /home/ahundt/src/real_good_robot/logs/2020-06-11-01-28-16_Sim-Rows-Two-Step-Reward-Masked-Testing/transitions/place-success-rate.log.csv
    > saving action efficiency: /home/ahundt/src/real_good_robot/logs/2020-06-11-01-28-16_Sim-Rows-Two-Step-Reward-Masked-Testing/transitions/action-efficiency.log.csv
    > saving plot: 2020-06-11-01-28-16_Sim-Rows-Two-Step-Reward-Masked-Testing-Sim-Rows-Two-Step-Reward-Masked-Testing_success_plot.png
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-06-11-01-28-16_Sim-Rows-Two-Step-Reward-Masked-Testing/data/best_stats.json
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-06-11-01-28-16_Sim-Rows-Two-Step-Reward-Masked-Testing/best_stats.json
    > Choosing a snapshot from the following options:{'trial_success_rate_best_value': 0.30666666666666664, 'trial_success_rate_best_index': 6477, 'grasp_success_rate_best_value': 0.9444444444444444, 'grasp_success_rate_best_index': 18688, 'place_success_rate_best_value': 1.0, 'place_success_rate_best_index': 8939, 'action_efficiency_best_value': 0.108, 'action_efficiency_best_index': 2758}
    > Evaluating trial_success_rate_best_value
    > Shapshot chosen: /home/ahundt/src/real_good_robot/logs/2020-06-07-14-07-53_Sim-Rows-Two-Step-Reward-Masked-Training/models/snapshot.reinforcement_trial_success_rate_best_value.pth
    > Random Testing Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-07-14-07-53_Sim-Rows-Two-Step-Reward-Masked-Training/2020-06-11-01-28-16_Sim-Rows-Two-Step-Reward-Masked-Testing
    > Random Testing results:
    >  {'trial_success_rate_best_value': -inf, 'trial_success_rate_best_index': None, 'grasp_success_rate_best_value': 1.0, 'grasp_success_rate_best_index': 1056, 'place_success_rate_best_value': 0.6666666666666666, 'place_success_rate_best_index': 1056, 'action_efficiency_best_value': 0.0, 'action_efficiency_best_index': 1056}
    > Training Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-07-14-07-53_Sim-Rows-Two-Step-Reward-Masked-Training
    > Training results:
    >  {'trial_success_rate_best_value': 0.30666666666666664, 'trial_success_rate_best_index': 6477, 'grasp_success_rate_best_value': 0.9444444444444444, 'grasp_success_rate_best_index': 18688, 'place_success_rate_best_value': 1.0, 'place_success_rate_best_index': 8939, 'action_efficiency_best_value': 0.108, 'action_efficiency_best_index': 2758}


    > Trial logging complete: 101 --------------------------------------------------------------
    > STACK:  trial: 101 actions/partial: 3.890909090909091  actions/full stack: 39.629629629629626 (lower is better)  Grasp Count: 6, grasp success rate: 1.0 place_on_stack_rate: 45.833333333333336 place_attempts: 6  partial_stack_successes: 275  stack_successes: 27 trial_success_rate: 0.26732673267326734 stack
    > goal: [1 3] current_height: 2
    > trial_complete_indices: [   8.   19.   27.   41.   50.   56.   59.   69.   77.   84.   98.  107.
    >   124.  134.  146.  151.  164.  167.  191.  198.  213.  225.  233.  244.
    >   253.  264.  273.  285.  308.  320.  333.  341.  343.  352.  361.  372.
    >   397.  408.  419.  429.  435.  445.  448.  455.  465.  480.  492.  509.
    >   519.  527.  536.  545.  558.  570.  573.  595.  600.  611.  622.  642.
    >   649.  666.  677.  684.  692.  700.  703.  717.  723.  729.  740.  752.
    >   760.  771.  776.  791.  802.  813.  819.  828.  840.  853.  864.  877.
    >   886.  896.  901.  910.  922.  935.  945.  957.  959. 1001. 1008. 1019.
    >  1027. 1036. 1046. 1056. 1069.]
    > Max trial success rate: 0.27, at action iteration: 1066. (total of 1068 actions, max excludes first 1066 actions)
    > /home/ahundt/src/real_good_robot/plot.py:136: RuntimeWarning: invalid value encountered in double_scalars
    >   success_rate[i] = float(successes.sum()) / float(grasp_count) if grasp_count > 0 else 0.0
    > Max grasp success rate: 1.0, at action iteration: 1066. (total of 1068 actions, max excludes first 1066 actions)
    > Max place success rate: 1.0, at action iteration: 1066. (total of 1069 actions, max excludes first 1066 actions)
    > Max action efficiency: 0.0, at action iteration: 1066. (total of 1069 actions, max excludes first 1066 actions)
    > saving trial success rate: /home/ahundt/src/real_good_robot/logs/2020-06-11-10-22-05_Sim-Rows-Two-Step-Reward-Masked-Testing/transitions/trial-success-rate.log.csv
    > saving grasp success rate: /home/ahundt/src/real_good_robot/logs/2020-06-11-10-22-05_Sim-Rows-Two-Step-Reward-Masked-Testing/transitions/grasp-success-rate.log.csv
    > saving place success rate: /home/ahundt/src/real_good_robot/logs/2020-06-11-10-22-05_Sim-Rows-Two-Step-Reward-Masked-Testing/transitions/place-success-rate.log.csv
    > saving action efficiency: /home/ahundt/src/real_good_robot/logs/2020-06-11-10-22-05_Sim-Rows-Two-Step-Reward-Masked-Testing/transitions/action-efficiency.log.csv
    > saving plot: 2020-06-11-10-22-05_Sim-Rows-Two-Step-Reward-Masked-Testing-Sim-Rows-Two-Step-Reward-Masked-Testing_success_plot.png
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-06-11-10-22-05_Sim-Rows-Two-Step-Reward-Masked-Testing/data/best_stats.json
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-06-11-10-22-05_Sim-Rows-Two-Step-Reward-Masked-Testing/best_stats.json
    > Choosing a snapshot from the following options:{'action_efficiency_best_index': 2758, 'action_efficiency_best_value': 0.108, 'grasp_success_rate_best_index': 18688, 'grasp_success_rate_best_value': 0.9444444444444444, 'place_success_rate_best_index': 8939, 'place_success_rate_best_value': 1.0, 'trial_success_rate_best_index': 6477, 'trial_success_rate_best_value': 0.30666666666666664}
    > Evaluating trial_success_rate_best_value
    > Shapshot chosen: /home/ahundt/src/real_good_robot/logs/2020-06-07-14-07-53_Sim-Rows-Two-Step-Reward-Masked-Training/models/snapshot.reinforcement_trial_success_rate_best_value.pth
    > Random Testing Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-07-14-07-53_Sim-Rows-Two-Step-Reward-Masked-Training/2020-06-11-10-22-05_Sim-Rows-Two-Step-Reward-Masked-Testing
    > Random Testing results:
    >  {'trial_success_rate_best_value': 0.27, 'trial_success_rate_best_index': 1066, 'grasp_success_rate_best_value': 1.0, 'grasp_success_rate_best_index': 1066, 'place_success_rate_best_value': 1.0, 'place_success_rate_best_index': 1066, 'action_efficiency_best_value': 0.0, 'action_efficiency_best_index': 1066}
    > Training Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-07-14-07-53_Sim-Rows-Two-Step-Reward-Masked-Training
    > Training results:
    >  {'action_efficiency_best_index': 2758, 'action_efficiency_best_value': 0.108, 'grasp_success_rate_best_index': 18688, 'grasp_success_rate_best_value': 0.9444444444444444, 'place_success_rate_best_index': 8939, 'place_success_rate_best_value': 1.0, 'trial_success_rate_best_index': 6477, 'trial_success_rate_best_value': 0.30666666666666664}

    manual action efficiency calculation: 100 trials * 6 ideal actions per trial / 1069 actions = 0.561


SIM STACK - Task Progress aka progress only - RANDOM ACTIONS - REWARD SCHEDULE 0.1, 1, 1 - workstation named spot 2020-06-08
----------------------------------------------------------------------------------------
export CUDA_VISIBLE_DEVICES="2" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 8 --push_rewards --experience_replay --explore_rate_decay --check_z_height --tcp_port 19999 --place --future_reward_discount 0.65 --max_train_actions 20000 --random_actions
Creating data logging session: /home/ahundt/src/real_good_robot/logs/2020-06-08-17-36-39_Sim-Stack-Two-Step-Reward-Training
Commit: 36a0c6a8cfd6c0d8a087f0b647814575054faedd  release tag:v0.16.3
GPU 2, Tab 2, port 19990, left v-rep window, v-rep tab 9

    > First model test result (second model pending)
    > ± '/home/ahundt/src/real_good_robot/logs/2020-06-08-17-36-39_Sim-Stack-Two-Step-Reward-Training/2020-06-12-03-47-07_Sim-Stack-Two-Step-Reward-Testing/best_stats.json' 
    > {"action_efficiency_best_index": 1542, "action_efficiency_best_value": 0.38132295719844356, "grasp_success_rate_best_index": 1542, "grasp_success_rate_best_value": 0.7957992998833139, "place_success_rate_best_index": 1544, "place_success_rate_best_value": 0.7259475218658892, "trial_success_rate_best_index": 1542, "trial_success_rate_best_value": 0.98}

    > Trial logging complete: 101 --------------------------------------------------------------
    > check_stack() stack_height: 1.0231710310697297 stack matches current goal: False partial_stack_success: False Does the code think a reset is needed: False
    > STACK:  trial: 101 actions/partial: 3.937125748502994  actions/full stack: 13.01980198019802 (lower is better)  Grasp Count: 735, grasp success rate: 0.7877551020408163 place_on_stack_rate: 0.5768566493955095 place_attempts: 579  partial_stack_successes: 334  stack_successes: 101 trial_success_rate: 1.0 stack goal: None current_height: 1.0231710310697297
    > trial_complete_indices: [   6.   20.   46.   50.   63.   67.   73.   87.   99.  111.  117.  152.
    >   158.  166.  181.  187.  197.  205.  209.  219.  232.  242.  250.  265.
    >   269.  278.  285.  293.  320.  326.  345.  355.  361.  373.  399.  406.
    >   452.  466.  493.  499.  507.  515.  532.  540.  546.  550.  557.  565.
    >   571.  577.  593.  601.  610.  618.  639.  643.  657.  664.  672.  678.
    >   700.  707.  723.  734.  750.  761.  770.  776.  813.  819.  823.  874.
    >   900.  910.  915.  928.  964.  968.  980.  988. 1014. 1023. 1027. 1035.
    >  1039. 1070. 1098. 1113. 1127. 1138. 1148. 1168. 1184. 1194. 1200. 1209.
    >  1225. 1237. 1261. 1305. 1314.]
    > Max trial success rate: 1.0, at action iteration: 1311. (total of 1313 actions, max excludes first 1311 actions)
    > Max grasp success rate: 0.7885402455661664, at action iteration: 1311. (total of 1313 actions, max excludes first 1311 actions)
    > Max place success rate: 0.7461139896373057, at action iteration: 1311. (total of 1314 actions, max excludes first 1311 actions)
    > Max action efficiency: 0.4622425629290618, at action iteration: 1313. (total of 1314 actions, max excludes first 1311 actions)
    > saving trial success rate: /home/ahundt/src/real_good_robot/logs/2020-06-12-10-30-14_Sim-Stack-Two-Step-Reward-Testing/transitions/trial-success-rate.log.csv
    > saving grasp success rate: /home/ahundt/src/real_good_robot/logs/2020-06-12-10-30-14_Sim-Stack-Two-Step-Reward-Testing/transitions/grasp-success-rate.log.csv
    > saving place success rate: /home/ahundt/src/real_good_robot/logs/2020-06-12-10-30-14_Sim-Stack-Two-Step-Reward-Testing/transitions/place-success-rate.log.csv
    > saving action efficiency: /home/ahundt/src/real_good_robot/logs/2020-06-12-10-30-14_Sim-Stack-Two-Step-Reward-Testing/transitions/action-efficiency.log.csv
    > saving plot: 2020-06-12-10-30-14_Sim-Stack-Two-Step-Reward-Testing-Sim-Stack-Two-Step-Reward-Testing_success_plot.png
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-06-12-10-30-14_Sim-Stack-Two-Step-Reward-Testing/data/best_stats.json
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-06-12-10-30-14_Sim-Stack-Two-Step-Reward-Testing/best_stats.json
    > Random Testing Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-08-17-36-39_Sim-Stack-Two-Step-Reward-Training/2020-06-12-10-30-14_Sim-Stack-Two-Step-Reward-Testing
    > Random Testing results:
    >  {'trial_success_rate_best_value': 1.0, 'trial_success_rate_best_index': 1311, 'grasp_success_rate_best_value': 0.7885402455661664, 'grasp_success_rate_best_index': 1311, 'place_success_rate_best_value': 0.7461139896373057, 'place_success_rate_best_index': 1311, 'action_efficiency_best_value': 0.4622425629290618, 'action_efficiency_best_index': 1313}
    > Training Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-08-17-36-39_Sim-Stack-Two-Step-Reward-Training
    > Training results:
    >  {'trial_success_rate_best_value': 0.8627450980392157, 'trial_success_rate_best_index': 17335, 'grasp_success_rate_best_value': 0.8943396226415095, 'grasp_success_rate_best_index': 18852, 'place_success_rate_best_value': 0.8398268398268398, 'place_success_rate_best_index': 17013, 'action_efficiency_best_value': 0.624, 'action_efficiency_best_index': 17020}



Resumed run
------------
RESUME pass 1 run (formerly gpu 1) on gpu 3, see /home/ahundt/src/real_good_robot/logs/2020-05-28-12-10-18_Sim-Rows-SPOT-Trial-Reward-Training near the top of this file














PASS 4 
========================================


PUSHING AND GRASPING WITH TRIAL REWARD & SAVE ALL MODELS ACCORDING TO BEST STATS - 2020-06-12
--------------------------------------
export CUDA_VISIBLE_DEVICES="0" && python3 main.py --is_sim --obj_mesh_dir objects/toys --num_obj 10 --push_rewards --experience_replay --explore_rate_decay  --tcp_port 19990 --common_sense --trial_reward --future_reward_discount 0.65 --random_actions --max_train_actions 5000
Commit: 60c816e2539f9b105f622132d1a6e22dc572caff  release tag:v0.16.4
Creating data logging session: /home/ahundt/src/real_good_robot/logs/2020-06-12-00-36-00_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Training
GPU 0, Tab 0, port 19990, left v-rep window, v-rep tab 7


RESUME: ± export CUDA_VISIBLE_DEVICES="0" && python3 main.py --is_sim --obj_mesh_dir objects/toys --num_obj 10 --push_rewards --experience_replay --explore_rate_decay  --tcp_port 19990 --common_sense --trial_reward --future_reward_discount 0.65 --random_actions --max_train_actions 5000 --resume /home/ahundt/src/real_good_robot/logs/2020-06-12-00-36-00_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Training
RESUME COMMIT: d0294ba8f84feea20ade3f3ec7ba9ba96a6b9371 (plotting crash bugfix)

± '/home/ahundt/src/real_good_robot/logs/2020-06-12-00-36-00_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Training/2020-06-13-07-52-11_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Testing/best_stats.json' 
Random testing:
{"grasp_action_efficiency_best_index": 1562, "grasp_action_efficiency_best_value": 0.6165172855313701, "grasp_success_rate_best_index": 1562, "grasp_success_rate_best_value": 0.7351145038167939, "trial_success_rate_best_index": 1562, "trial_success_rate_best_value": 0.98989898989899}

testing challenging arrangements:± 
'/home/ahundt/src/real_good_robot/logs/2020-06-12-00-36-00_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Training/2020-06-13-15-04-48_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Challenging-Arrangements/best_stats.json' 
{"grasp_action_efficiency_best_index": 1442, "grasp_action_efficiency_best_value": 0.3393476752255378, "grasp_success_rate_best_index": 1442, "grasp_success_rate_best_value": 0.443336355394379, "senarios_100_percent_complete": 6, "trial_success_rate_best_index": 1441, "trial_success_rate_best_value": 0.9541284403669725}



PUSHING AND GRASPING WITH TASK PROGRESS & SAVE ALL MODELS ACCORDING TO BEST STATS - 2020-06-13
--------------------------------------
export CUDA_VISIBLE_DEVICES="0" && python3 main.py --is_sim --obj_mesh_dir objects/toys --num_obj 10 --push_rewards --experience_replay --explore_rate_decay --tcp_port 19990 --common_sense --future_reward_discount 0.65  --random_actions  --max_train_actions 5000
Commit: 60c816e2539f9b105f622132d1a6e22dc572caff  release tag:v0.16.4
Creating data logging session: 
GPU 0, Tab 0, port 19990, left v-rep window, v-rep tab 7




Parameter sensitivity experiment - SIM ROW - Task Progress SPOT-Q MASKED - REWARD SCHEDULE 0.5, 1, 1 - workstation named spot 2020-06-12
----------------------------------------------------------------------------------------
export CUDA_VISIBLE_DEVICES="1" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 4 --push_rewards --experience_replay --explore_rate_decay --check_row --tcp_port 19998 --place --future_reward_discount 0.65 --max_train_actions 20000 --random_actions --common_sense
Creating data logging session: /home/ahundt/src/real_good_robot/logs/2020-06-11-23-41-01_Sim-Rows-Two-Step-Reward-Masked-Training
Commit: ff54ed3ae8b700b12433897e680362675cd31013  release tag:push_r_weight_0.5_v1
GPU 1, Tab 1, port 19998, center left v-rep window, v-rep tab 8











ANY OBJECT SIM STACK  - Trial Reward SPOT-Q MASKED - RANDOM ACTIONS - REWARD SCHEDULE 0.1, 1, 1 - EFFICIENTNET 1 dilation - workstation named spot 2020-06-03
----------------------------------------------------------------------------------------
export CUDA_VISIBLE_DEVICES="2" && python3 main.py --is_sim --obj_mesh_dir objects/toys --num_obj 8 --push_rewards --experience_replay --explore_rate_decay --check_z_height --tcp_port 19999 --place --future_reward_discount 0.65 --max_train_actions 20000 --random_actions --trial_reward --common_sense --nn efficientnet --num_dilation 1
Creating data logging session: 
Commit: 60c816e2539f9b105f622132d1a6e22dc572caff  release tag:v0.16.4
GPU 2, Tab 2, port 19999, right v-rep window, v-rep tab 10






Resumed run
------------
RESUME pass 1 run (formerly gpu 0) on gpu 3, see /home/ahundt/src/real_good_robot/logs/2020-05-28-12-09-32_Sim-Stack-SPOT-Trial-Reward-Training near the top of this file











PASS 5 - efficientnet
=======




PUSHING AND GRASPING WITH TRIAL REWARD & SAVE ALL MODELS ACCORDING TO BEST STATS - EFFICIENTNET 1 dilation - 2020-06-26
--------------------------------------
export CUDA_VISIBLE_DEVICES="0" && python3 main.py --is_sim --obj_mesh_dir objects/toys --num_obj 10 --push_rewards --experience_replay --explore_rate_decay  --tcp_port 19990 --common_sense --trial_reward --future_reward_discount 0.65 --random_actions --max_train_actions 5000 --nn efficientnet --num_dilation 1
Commit: cca5887217884d862167edbf31ffaf4d1d21a863  release tag:v0.16.5
Creating data logging session: /home/ahundt/src/real_good_robot/logs/2020-06-26-15-10-40_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Training
GPU 0, Tab 0, port 19990, left v-rep window, v-rep tab 7


    > Trial logging complete: 110 --------------------------------------------------------------
    > Running two step backprop()
    > Primitive confidence scores: 0.746463 (push), 1.726852 (grasp)
    > Action: grasp at (4, 92, 83)
    > Training loss: 0.057178
    > prev_height: 0.0 max_z: 0.05111149809658745 goal_success: True needed to reset: False max_workspace_height: -0.02 <<<<<<<<<<<
    > Grasp Count: 986, grasp success rate: 0.513184584178499
    > trial_complete_indices: [  6.  13.  17.  28.  39.  54.  61.  70.  79.  85.  96. 106. 118. 132.
    >  146. 156. 163. 170. 178. 187. 192. 199. 207. 210. 212. 218. 222. 229.
    >  233. 240. 250. 264. 279. 286. 296. 308. 322. 337. 349. 360. 370. 377.
    >  390. 398. 404. 415. 424. 430. 438. 444. 454. 463. 473. 481. 487. 495.
    >  503. 508. 516. 523. 530. 535. 541. 546. 551. 556. 562. 566. 575. 583.
    >  593. 606. 615. 628. 641. 651. 660. 670. 682. 688. 698. 714. 730. 744.
    >  756. 767. 775. 781. 805. 813. 821. 827. 836. 847. 854. 860. 865. 871.
    >  880. 889. 897. 909. 916. 924. 936. 942. 953. 965. 979. 990.]
    > Max trial success rate: 1.0, at action iteration: 987. (total of 989 actions, max excludes first 987 actions)
    > max trial successes: 110.0
    > individual_arrangement_trial_success_rate: [1.  1.  0.9 1.  1.  1.  1.  1.  1.  1.  0.9]
    > senarios_100_percent_complete: 9
    > Max grasp success rate: 0.513733468972533, at action iteration: 987. (total of 989 actions, max excludes first 987 actions)
    > Max grasp action efficiency: 0.5116514690982776, at action iteration: 987. (total of 990 actions, max excludes first 987 actions)
    > saving trial success rate: /home/ahundt/src/real_good_robot/logs/2020-06-27-18-18-07_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Challenging-Arrangements/transitions/trial-success-rate.log.csv
    > saving grasp success rate: /home/ahundt/src/real_good_robot/logs/2020-06-27-18-18-07_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Challenging-Arrangements/transitions/grasp-success-rate.log.csv
    > saving action efficiency: /home/ahundt/src/real_good_robot/logs/2020-06-27-18-18-07_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Challenging-Arrangements/transitions/action-efficiency.log.csv
    > saving plot: 2020-06-27-18-18-07_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Challenging-Arrangements-Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Challenging-Arrangements_success_plot.png
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-06-27-18-18-07_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Challenging-Arrangements/data/best_stats.json
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-06-27-18-18-07_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Challenging-Arrangements/best_stats.json
    > Challenging Arrangements Preset Testing Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-26-15-10-40_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Training/2020-06-27-18-18-07_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Challenging-Arrangements
    > Challenging Arrangements Preset Testing results:
    >  {'trial_success_rate_best_value': 1.0, 'trial_success_rate_best_index': 987, 'senarios_100_percent_complete': 9, 'grasp_success_rate_best_value': 0.513733468972533, 'grasp_success_rate_best_index': 987, 'grasp_action_efficiency_best_value': 0.5116514690982776, 'grasp_action_efficiency_best_index': 987}
    > Choosing a snapshot from the following options:{'trial_success_rate_best_value': 1.0, 'trial_success_rate_best_index': 675, 'grasp_success_rate_best_value': 0.8714285714285714, 'grasp_success_rate_best_index': 4705, 'grasp_action_efficiency_best_value': 0.854, 'grasp_action_efficiency_best_index': 4705}
    > Evaluating trial_success_rate_best_value
    > Shapshot chosen: /home/ahundt/src/real_good_robot/logs/2020-06-26-15-10-40_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Training/models/snapshot.reinforcement_trial_success_rate_best_value.pth
    > Challenging Arrangements Preset Testing Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-26-15-10-40_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Training/2020-06-27-18-18-07_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Challenging-Arrangements
    > Challenging Arrangements Preset Testing results:
    >  {'trial_success_rate_best_value': 1.0, 'trial_success_rate_best_index': 987, 'senarios_100_percent_complete': 9, 'grasp_success_rate_best_value': 0.513733468972533, 'grasp_success_rate_best_index': 987, 'grasp_action_efficiency_best_value': 0.5116514690982776, 'grasp_action_efficiency_best_index': 987}
    > Random Testing Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-26-15-10-40_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Training/2020-06-27-13-00-19_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Testing
    > Random Testing results:
    >  {'trial_success_rate_best_value': 1.0, 'trial_success_rate_best_index': 1133, 'grasp_success_rate_best_value': 0.8499558693733451, 'grasp_success_rate_best_index': 1133, 'grasp_action_efficiency_best_value': 0.8499558693733451, 'grasp_action_efficiency_best_index': 1133}
    > Training Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-26-15-10-40_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Training
    > Training results:
    >  {'trial_success_rate_best_value': 1.0, 'trial_success_rate_best_index': 675, 'grasp_success_rate_best_value': 0.8714285714285714, 'grasp_success_rate_best_index': 4705, 'grasp_action_efficiency_best_value': 0.854, 'grasp_action_efficiency_best_index': 4705}




PUSHING AND GRASPING WITH TRIAL REWARD & SAVE ALL MODELS ACCORDING TO BEST STATS - EFFICIENTNET 1 dilation - 2020-06-28
--------------------------------------
export CUDA_VISIBLE_DEVICES="0" && python3 main.py --is_sim --obj_mesh_dir objects/toys --num_obj 10 --push_rewards --experience_replay --explore_rate_decay  --tcp_port 19990 --common_sense --trial_reward --future_reward_discount 0.65 --random_actions --max_train_actions 5000 --nn efficientnet --num_dilation 1
Commit: cca5887217884d862167edbf31ffaf4d1d21a863  release tag:v0.16.5
Creating data logging session: /home/ahundt/src/real_good_robot/logs/2020-06-28-10-45-13_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Training
GPU 0, Tab 0, port 19990, left v-rep window, v-rep tab 7


    > Trial logging complete: 110 --------------------------------------------------------------
    > Running two step backprop()
    > Primitive confidence scores: 1.113376 (push), 1.805528 (grasp)
    > Action: grasp at (13, 139, 115)
    > Training loss: 0.197310
    > Executing: grasp at (-0.494000, 0.054000, 0.050216) orientation: 5.105088
    > gripper position: 0.0528782494366169
    > gripper position: 0.034795910120010376
    > gripper position: 0.033892154693603516
    > gripper position: 0.03291165828704834
    > Grasp successful: False
    > prev_height: 0.0 max_z: 0.0667136022755871 goal_success: True needed to reset: False max_workspace_height: -0.02 <<<<<<<<<<<
    > Grasp Count: 852, grasp success rate: 0.5880281690140845
    > trial_complete_indices: [  8.  18.  33.  41.  48.  58.  69.  84.  95. 101. 108. 120. 127. 134.
    >  140. 152. 160. 169. 179. 191. 196. 202. 208. 214. 221. 227. 232. 236.
    >  241. 255. 268. 275. 286. 301. 316. 328. 343. 358. 368. 378. 384. 391.
    >  400. 408. 420. 426. 434. 441. 449. 455. 464. 472. 481. 492. 501. 509.
    >  518. 527. 538. 546. 551. 555. 559. 566. 570. 576. 580. 586. 590. 594.
    >  606. 615. 624. 632. 640. 647. 655. 662. 670. 682. 696. 709. 721. 733.
    >  753. 765. 780. 794. 809. 823. 829. 837. 847. 858. 866. 873. 883. 896.
    >  910. 916. 924. 932. 941. 947. 953. 963. 969. 975. 984. 992.]
    > Max trial success rate: 1.0, at action iteration: 989. (total of 991 actions, max excludes first 989 actions)
    > max trial successes: 110.0
    > individual_arrangement_trial_success_rate: [1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.9]
    > senarios_100_percent_complete: 10
    > Max grasp success rate: 0.5882352941176471, at action iteration: 990. (total of 991 actions, max excludes first 989 actions)
    > Max grasp action efficiency: 0.506572295247725, at action iteration: 991. (total of 992 actions, max excludes first 989 actions)
    > saving trial success rate: /home/ahundt/src/real_good_robot/logs/2020-06-29-13-27-18_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Challenging-Arrangements/transitions/trial-success-rate.log.csv
    > saving grasp success rate: /home/ahundt/src/real_good_robot/logs/2020-06-29-13-27-18_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Challenging-Arrangements/transitions/grasp-success-rate.log.csv
    > saving action efficiency: /home/ahundt/src/real_good_robot/logs/2020-06-29-13-27-18_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Challenging-Arrangements/transitions/action-efficiency.log.csv
    > saving plot: 2020-06-29-13-27-18_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Challenging-Arrangements-Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Challenging-Arrangements_success_plot.png
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-06-29-13-27-18_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Challenging-Arrangements/data/best_stats.json
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-06-29-13-27-18_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Challenging-Arrangements/best_stats.json
    > Challenging Arrangements Preset Testing Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-28-10-45-13_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Training/2020-06-29-13-27-18_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Challenging-Arrangements
    > Challenging Arrangements Preset Testing results:
    >  {'trial_success_rate_best_value': 1.0, 'trial_success_rate_best_index': 989, 'senarios_100_percent_complete': 10, 'grasp_success_rate_best_value': 0.5882352941176471, 'grasp_success_rate_best_index': 990, 'grasp_action_efficiency_best_value': 0.506572295247725, 'grasp_action_efficiency_best_index': 991}
    > Choosing a snapshot from the following options:{'trial_success_rate_best_value': 1.0232558139534884, 'trial_success_rate_best_index': 4999, 'grasp_success_rate_best_value': 0.8843813387423936, 'grasp_success_rate_best_index': 4768, 'grasp_action_efficiency_best_value': 0.872, 'grasp_action_efficiency_best_index': 4768}
    > Evaluating trial_success_rate_best_value
    > Shapshot chosen: /home/ahundt/src/real_good_robot/logs/2020-06-28-10-45-13_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Training/models/snapshot.reinforcement_trial_success_rate_best_value.pth
    > Challenging Arrangements Preset Testing Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-28-10-45-13_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Training/2020-06-29-13-27-18_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Challenging-Arrangements
    > Challenging Arrangements Preset Testing results:
    >  {'trial_success_rate_best_value': 1.0, 'trial_success_rate_best_index': 989, 'senarios_100_percent_complete': 10, 'grasp_success_rate_best_value': 0.5882352941176471, 'grasp_success_rate_best_index': 990, 'grasp_action_efficiency_best_value': 0.506572295247725, 'grasp_action_efficiency_best_index': 991}
    > Random Testing Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-28-10-45-13_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Training/2020-06-29-08-15-52_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Testing
    > Random Testing results:
    >  {'trial_success_rate_best_value': 1.0, 'trial_success_rate_best_index': 1122, 'grasp_success_rate_best_value': 0.8556053811659193, 'grasp_success_rate_best_index': 1122, 'grasp_action_efficiency_best_value': 0.8502673796791443, 'grasp_action_efficiency_best_index': 1122}
    > Training Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-28-10-45-13_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Training
    > Training results:
    >  {'trial_success_rate_best_value': 1.0232558139534884, 'trial_success_rate_best_index': 4999, 'grasp_success_rate_best_value': 0.8843813387423936, 'grasp_success_rate_best_index': 4768, 'grasp_action_efficiency_best_value': 0.872, 'grasp_action_efficiency_best_index': 4768}





ANY OBJECT SIM STACK  - Task Progress SPOT-Q MASKED - RANDOM ACTIONS - REWARD SCHEDULE 0.1, 1, 1 - EFFICIENTNET 1 dilation - workstation named spot 2020-06-26
----------------------------------------------------------------------------------------
export CUDA_VISIBLE_DEVICES="1" && python3 main.py --is_sim --obj_mesh_dir objects/toys --num_obj 8 --push_rewards --experience_replay --explore_rate_decay --check_z_height --tcp_port 19998 --place --future_reward_discount 0.65 --max_train_actions 20000 --random_actions --common_sense --nn efficientnet --num_dilation 1
Creating data logging session: /home/ahundt/src/real_good_robot/logs/2020-06-26-15-13-25_Sim-Stack-Two-Step-Reward-Masked-Training                                                                                                                                                                     
Commit: cca5887217884d862167edbf31ffaf4d1d21a863  release tag:v0.16.5
GPU 1, Tab 1, port 19998, right center v-rep window, v-rep tab 8



    > Trial logging complete: 101 --------------------------------------------------------------
    > STACK:  trial: 101 actions/partial: 29.161125319693095  actions/full stack: 438.53846153846155 (lower is better)  Grasp Count: 6677, grasp success rate: 0.5800509210723379 place_on_stack_rate: 0.1013215859030837 place_attempts: 3859  partial_stack_successes: 391  stack_successes: 26 trial_success_rate: 0.25742574257425743 stack goal: None current_height: 1.3412568889607048
    > trial_complete_indices: [  225.   366.   460.   571.   752.   835.   966.  1122.  1221.  1364.
    >   1492.  1545.  1680.  1741.  1829.  1895.  2040.  2189.  2443.  2554.
    >   2714.  2753.  2810.  2856.  2985.  3120.  3295.  3416.  3508.  3572.
    >   3669.  3732.  3862.  3938.  4024.  4085.  4112.  4175.  4186.  4342.
    >   4492.  4677.  4749.  4904.  5083.  5167.  5297.  5412.  5581.  5698.
    >   5896.  5922.  6073.  6167.  6269.  6355.  6659.  6714.  6743.  6894.
    >   6975.  7053.  7116.  7211.  7342.  7418.  7519.  7549.  7796.  7820.
    >   7858.  8041.  8109.  8183.  8428.  8638.  8894.  9005.  9114.  9337.
    >   9464.  9686.  9738.  9817.  9961. 10015. 10145. 10193. 10328. 10366.
    >  10445. 10548. 10626. 10742. 10764. 10848. 10865. 11031. 11197. 11315.
    >  11401.]
    > Max trial success rate: 0.26, at action iteration: 11398. (total of 11400 actions, max excludes first 11398 actions)
    > Max grasp success rate: 0.5801618219958046, at action iteration: 11398. (total of 11400 actions, max excludes first 11398 actions)
    > Max place success rate: 0.5263492063492063, at action iteration: 11398. (total of 11401 actions, max excludes first 11398 actions)
    > Max action efficiency: 0.015265836111598525, at action iteration: 11398. (total of 11401 actions, max excludes first 11398 actions)
    > saving trial success rate: /home/ahundt/src/real_good_robot/logs/2020-07-02-14-53-00_Sim-Stack-Two-Step-Reward-Masked-Testing/transitions/trial-success-rate.log.csv
    > saving grasp success rate: /home/ahundt/src/real_good_robot/logs/2020-07-02-14-53-00_Sim-Stack-Two-Step-Reward-Masked-Testing/transitions/grasp-success-rate.log.csv
    > saving place success rate: /home/ahundt/src/real_good_robot/logs/2020-07-02-14-53-00_Sim-Stack-Two-Step-Reward-Masked-Testing/transitions/place-success-rate.log.csv
    > saving action efficiency: /home/ahundt/src/real_good_robot/logs/2020-07-02-14-53-00_Sim-Stack-Two-Step-Reward-Masked-Testing/transitions/action-efficiency.log.csv
    > saving plot: 2020-07-02-14-53-00_Sim-Stack-Two-Step-Reward-Masked-Testing-Sim-Stack-Two-Step-Reward-Masked-Testing_success_plot.png
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-07-02-14-53-00_Sim-Stack-Two-Step-Reward-Masked-Testing/data/best_stats.json
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-07-02-14-53-00_Sim-Stack-Two-Step-Reward-Masked-Testing/best_stats.json
    > Random Testing Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-26-15-13-25_Sim-Stack-Two-Step-Reward-Masked-Training/2020-06-30-05-17-35_Sim-Stack-Two-Step-Reward-Masked-Testing
    > Random Testing results:
    >  {'trial_success_rate_best_value': 0.47, 'trial_success_rate_best_index': 13484, 'grasp_success_rate_best_value': 0.7247529834466829, 'grasp_success_rate_best_index': 13484, 'place_success_rate_best_value': 0.5312719606465214, 'place_success_rate_best_index': 13486, 'action_efficiency_best_value': 0.027588252743992882, 'action_efficiency_best_index': 13486}
    > Training Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-26-15-13-25_Sim-Stack-Two-Step-Reward-Masked-Training
    > Training results:
    >  {'trial_success_rate_best_value': 0.25, 'trial_success_rate_best_index': 13316, 'grasp_success_rate_best_value': 0.8694029850746269, 'grasp_success_rate_best_index': 18482, 'place_success_rate_best_value': 0.6090909090909091, 'place_success_rate_best_index': 8898, 'action_efficiency_best_value': 1.164, 'action_efficiency_best_index': 6812}









SIM STACK - Task Progress SPOT-Q MASKED - RANDOM ACTIONS - REWARD SCHEDULE 0.1, 1, 1 - EFFICIENTNET 1 dilation - workstation named spot 2020-06-26
----------------------------------------------------------------------------------------
export CUDA_VISIBLE_DEVICES="2" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 8 --push_rewards --experience_replay --explore_rate_decay --check_z_height --tcp_port 19999 --place --future_reward_discount 0.65 --max_train_actions 20000 --random_actions --common_sense --nn efficientnet --num_dilation 1
Creating data logging session: /home/ahundt/src/real_good_robot/logs/2020-06-26-15-17-08_Sim-Stack-Two-Step-Reward-Masked-Training
Commit: cca5887217884d862167edbf31ffaf4d1d21a863  release tag:v0.16.5
GPU 2, Tab 2, port 19999, right center v-rep window, v-rep tab 9


    > Trial logging complete: 101 --------------------------------------------------------------
    > prev_height: 0.0 max_z: 0.051130634964013114 goal_success: True needed to reset: False max_workspace_height: -0.02 <<<<<<<<<<<
    > prev_height: 1.0 max_z: 1.0226126992802622 goal_success: False needed to reset: False max_workspace_height: 0.6 <<<<<<<<<<<
    > check_stack() stack_height: 1.0226126992802622 stack matches current goal: False partial_stack_success: False Does the code think a reset is needed: False
    > STACK:  trial: 101 actions/partial: 3.0235690235690234  actions/full stack: 8.98 (lower is better)  Grasp Count: 488, grasp success rate: 0.8422131147540983 place_on_stack_rate: 0.724390243902439 place_attempts: 410  partial_stack_successes: 297  stack_successes: 100 trial_success_rate: 0.9900990099009901 stack goal: None current_height: 1.0226126992802622
    > trial_complete_indices: [  6.  20.  32.  38.  47.  53.  61.  69.  73.  78.  88.  93.  99. 105.
    >  113. 119. 125. 137. 145. 149. 155. 159. 171. 186. 194. 198. 203. 214.
    >  224. 230. 236. 244. 253. 259. 265. 275. 281. 287. 293. 301. 311. 322.
    >  330. 342. 350. 361. 368. 374. 383. 390. 398. 402. 418. 425. 433. 441.
    >  445. 453. 457. 471. 479. 485. 492. 502. 550. 559. 575. 581. 587. 595.
    >  599. 606. 616. 628. 634. 638. 649. 656. 666. 674. 680. 686. 691. 700.
    >  707. 711. 717. 729. 735. 743. 753. 762. 769. 775. 785. 803. 815. 823.
    >  880. 889. 897.]
    > Max trial success rate: 0.99, at action iteration: 894. (total of 896 actions, max excludes first 894 actions)
    > Max grasp success rate: 0.8436213991769548, at action iteration: 894. (total of 896 actions, max excludes first 894 actions)
    > Max place success rate: 0.8484107579462102, at action iteration: 894. (total of 897 actions, max excludes first 894 actions)
    > Max action efficiency: 0.6711409395973155, at action iteration: 896. (total of 897 actions, max excludes first 894 actions)
    > saving trial success rate: /home/ahundt/src/real_good_robot/logs/2020-06-30-10-36-48_Sim-Stack-Two-Step-Reward-Masked-Testing/transitions/trial-success-rate.log.csv
    > saving grasp success rate: /home/ahundt/src/real_good_robot/logs/2020-06-30-10-36-48_Sim-Stack-Two-Step-Reward-Masked-Testing/transitions/grasp-success-rate.log.csv
    > saving place success rate: /home/ahundt/src/real_good_robot/logs/2020-06-30-10-36-48_Sim-Stack-Two-Step-Reward-Masked-Testing/transitions/place-success-rate.log.csv
    > saving action efficiency: /home/ahundt/src/real_good_robot/logs/2020-06-30-10-36-48_Sim-Stack-Two-Step-Reward-Masked-Testing/transitions/action-efficiency.log.csv
    > saving plot: 2020-06-30-10-36-48_Sim-Stack-Two-Step-Reward-Masked-Testing-Sim-Stack-Two-Step-Reward-Masked-Testing_success_plot.png
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-06-30-10-36-48_Sim-Stack-Two-Step-Reward-Masked-Testing/data/best_stats.json
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-06-30-10-36-48_Sim-Stack-Two-Step-Reward-Masked-Testing/best_stats.json
    > Random Testing Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-26-15-17-08_Sim-Stack-Two-Step-Reward-Masked-Training/2020-06-30-06-33-03_Sim-Stack-Two-Step-Reward-Masked-Testing
    > Random Testing results: 
    >  {'trial_success_rate_best_value': 0.99, 'trial_success_rate_best_index': 823, 'grasp_success_rate_best_value': 0.9133489461358314, 'grasp_success_rate_best_index': 823, 'place_success_rate_best_value': 0.8513853904282116, 'place_success_rate_best_index': 823, 'action_efficiency_best_value': 0.7290400972053463, 'action_efficiency_best_index': 825}
    > Training Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-26-15-17-08_Sim-Stack-Two-Step-Reward-Masked-Training
    > Training results: 
    >  {'trial_success_rate_best_value': 0.9054054054054054, 'trial_success_rate_best_index': 15101, 'grasp_success_rate_best_value': 0.9683794466403162, 'grasp_success_rate_best_index': 12884, 'place_success_rate_best_value': 0.9267241379310345, 'place_success_rate_best_index': 13640, 'action_efficiency_best_value': 0.864, 'action_efficiency_best_index': 13081}





SIM ROW - Task Progress SPOT-Q MASKED - REWARD SCHEDULE 0.1, 1, 1 - EFFICIENTNET 1 dilation - workstation named spot 2020-06-26
----------------------------------------------------------------------------------------
export CUDA_VISIBLE_DEVICES="3" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 4 --push_rewards --experience_replay --explore_rate_decay --check_row --tcp_port 20000 --place --future_reward_discount 0.65 --max_train_actions 20000 --random_actions --common_sense --nn efficientnet --num_dilation 1
Creating data logging session: /home/ahundt/src/real_good_robot/logs/2020-06-26-15-18-44_Sim-Rows-Two-Step-Reward-Masked-Training
Commit: cca5887217884d862167edbf31ffaf4d1d21a863  release tag:v0.16.5
GPU 3, Tab 3, port 20000, right v-rep window, v-rep tab 10

    > Trial logging complete: 101 --------------------------------------------------------------
    > prev_height: 0.0 max_z: 0.05110832959176721 goal_success: True needed to reset: False max_workspace_height: -0.02 <<<<<<<<<<<
    > check_row: False | row_size: 1 | blocks: []
    > check_stack() stack_height: 1 stack matches current goal: True partial_stack_success: False Does the code think a reset is needed: False
    > STACK:  trial: 101 actions/partial: 5.036144578313253  actions/full stack: 12.666666666666666 (lower is better)  Grasp Count: 677, grasp success rate: 0.8552437223042836 place_on_stack_rate: 0.43154246100519933 place_attempts: 577  partial_stack_successes: 249  stack_successes: 99 trial_success_rate: 0.9801980198019802 stack goal: [2 1] current_height: 1
    > trial_complete_indices: [   4.    8.   14.   22.   34.   51.   55.   59.   63.   78.   88.   98.
    >   105.  139.  143.  164.  166.  188.  195.  214.  218.  224.  232.  237.
    >   276.  282.  287.  307.  340.  344.  352.  364.  368.  372.  390.  398.
    >   402.  419.  421.  425.  450.  460.  468.  490.  494.  502.  508.  522.
    >   524.  529.  541.  547.  661.  713.  717.  754.  774.  782.  804.  816.
    >   822.  829.  834.  838.  842.  847.  849.  856.  885.  889.  894.  932.
    >   934.  953.  983. 1006. 1010. 1018. 1030. 1040. 1044. 1078. 1110. 1118.
    >  1136. 1140. 1151. 1153. 1161. 1167. 1183. 1189. 1195. 1214. 1218. 1220.
    >  1226. 1236. 1240. 1244. 1253.]
    > Max trial success rate: 0.98, at action iteration: 1250. (total of 1252 actions, max excludes first 1250 actions)
    > Max grasp success rate: 0.8562962962962963, at action iteration: 1250. (total of 1252 actions, max excludes first 1250 actions)
    > Max place success rate: 0.7013888888888888, at action iteration: 1250. (total of 1253 actions, max excludes first 1250 actions)
    > Max action efficiency: 0.4896, at action iteration: 1252. (total of 1253 actions, max excludes first 1250 actions)
    > saving trial success rate: /home/ahundt/src/real_good_robot/logs/2020-06-30-14-25-16_Sim-Rows-Two-Step-Reward-Masked-Testing/transitions/trial-success-rate.log.csv
    > saving grasp success rate: /home/ahundt/src/real_good_robot/logs/2020-06-30-14-25-16_Sim-Rows-Two-Step-Reward-Masked-Testing/transitions/grasp-success-rate.log.csv
    > saving place success rate: /home/ahundt/src/real_good_robot/logs/2020-06-30-14-25-16_Sim-Rows-Two-Step-Reward-Masked-Testing/transitions/place-success-rate.log.csv
    > saving action efficiency: /home/ahundt/src/real_good_robot/logs/2020-06-30-14-25-16_Sim-Rows-Two-Step-Reward-Masked-Testing/transitions/action-efficiency.log.csv
    > saving plot: 2020-06-30-14-25-16_Sim-Rows-Two-Step-Reward-Masked-Testing-Sim-Rows-Two-Step-Reward-Masked-Testing_success_plot.png
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-06-30-14-25-16_Sim-Rows-Two-Step-Reward-Masked-Testing/data/best_stats.json
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-06-30-14-25-16_Sim-Rows-Two-Step-Reward-Masked-Testing/best_stats.json
    > Random Testing Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-26-15-18-44_Sim-Rows-Two-Step-Reward-Masked-Training/2020-06-30-14-25-16_Sim-Rows-Two-Step-Reward-Masked-Testing
    > Random Testing results:
    >  {'trial_success_rate_best_value': 0.98, 'trial_success_rate_best_index': 1250, 'grasp_success_rate_best_value': 0.8562962962962963, 'grasp_success_rate_best_index': 1250, 'place_success_rate_best_value': 0.7013888888888888, 'place_success_rate_best_index': 1250, 'action_efficiency_best_value': 0.4896, 'action_efficiency_best_index': 1252}
    > Training Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-26-15-18-44_Sim-Rows-Two-Step-Reward-Masked-Training
    > Training results:
    >  {'trial_success_rate_best_value': 0.5869565217391305, 'trial_success_rate_best_index': 13103, 'grasp_success_rate_best_value': 0.7921146953405018, 'grasp_success_rate_best_index': 15530, 'place_success_rate_best_value': 0.7102803738317757, 'place_success_rate_best_index': 15717, 'action_efficiency_best_value': 0.708, 'action_efficiency_best_index': 15733}















SIM STACK - Task Progress SPOT-Q MASKED - RANDOM ACTIONS - REWARD SCHEDULE 0.1, 1, 1 - EFFICIENTNET 1 dilation - workstation named spot 2020-06-30
----------------------------------------------------------------------------------------
export CUDA_VISIBLE_DEVICES="2" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 8 --push_rewards --experience_replay --explore_rate_decay --check_z_height --tcp_port 19999 --place --future_reward_discount 0.65 --max_train_actions 20000 --random_actions --common_sense --nn efficientnet --num_dilation 1
Creating data logging session: /home/ahundt/src/real_good_robot/logs/2020-06-30-17-27-56_Sim-Stack-Two-Step-Reward-Masked-Training
Commit: cca5887217884d862167edbf31ffaf4d1d21a863  release tag:v0.16.5
GPU 2, Tab 2, port 19999, right center v-rep window, v-rep tab 9


    > Trial logging complete: 101 --------------------------------------------------------------
    > check_stack() stack_height: 1.0228815123259785 stack matches current goal: False partial_stack_success: False Does the code think a reset is needed: False
    > STACK:  trial: 101 actions/partial: 3.623342175066313  actions/full stack: 13.797979797979798 (lower is better)  Grasp Count: 748, grasp success rate: 0.8275401069518716 place_on_stack_rate: 0.610032362459547 place_attempts: 618  partial_stack_successes: 377  stack_successes: 99 trial_success_rate: 0.9801980198019802 stack goal: None current_height: 1.0228815123259785
    > trial_complete_indices: [  10.  158.  178.  186.  198.  214.  223.  231.  235.  241.  253.  259.
    >   265.  285.  307.  311.  359.  365.  373.  395.  405.  416.  424.  432.
    >   442.  449.  457.  463.  489.  536.  566.  572.  576.  582.  602.  609.
    >   613.  642.  648.  731.  738.  745.  751.  760.  764.  770.  777.  783.
    >   790.  796.  816.  823.  829.  833.  849.  870.  888.  898.  908.  920.
    >   941.  953.  970.  977. 1009. 1015. 1028. 1034. 1040. 1050. 1061. 1071.
    >  1079. 1086. 1092. 1107. 1121. 1127. 1133. 1142. 1156. 1167. 1175. 1181.
    >  1194. 1198. 1211. 1222. 1229. 1235. 1241. 1261. 1270. 1277. 1303. 1335.
    >  1341. 1347. 1355. 1361. 1365.]
    > Max trial success rate: 0.97, at action iteration: 1362. (total of 1364 actions, max excludes first 1362 actions)
    > Max grasp success rate: 0.8284182305630027, at action iteration: 1362. (total of 1364 actions, max excludes first 1362 actions)
    > Max place success rate: 0.7828200972447326, at action iteration: 1362. (total of 1365 actions, max excludes first 1362 actions)
    > Max action efficiency: 0.43612334801762115, at action iteration: 1364. (total of 1365 actions, max excludes first 1362 actions)
    > saving trial success rate: /home/ahundt/src/real_good_robot/logs/2020-07-04-14-12-00_Sim-Stack-Two-Step-Reward-Masked-Testing/transitions/trial-success-rate.log.csv
    > saving grasp success rate: /home/ahundt/src/real_good_robot/logs/2020-07-04-14-12-00_Sim-Stack-Two-Step-Reward-Masked-Testing/transitions/grasp-success-rate.log.csv
    > saving place success rate: /home/ahundt/src/real_good_robot/logs/2020-07-04-14-12-00_Sim-Stack-Two-Step-Reward-Masked-Testing/transitions/place-success-rate.log.csv
    > saving action efficiency: /home/ahundt/src/real_good_robot/logs/2020-07-04-14-12-00_Sim-Stack-Two-Step-Reward-Masked-Testing/transitions/action-efficiency.log.csv
    > saving plot: 2020-07-04-14-12-00_Sim-Stack-Two-Step-Reward-Masked-Testing-Sim-Stack-Two-Step-Reward-Masked-Testing_success_plot.png
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-07-04-14-12-00_Sim-Stack-Two-Step-Reward-Masked-Testing/data/best_stats.json
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-07-04-14-12-00_Sim-Stack-Two-Step-Reward-Masked-Testing/best_stats.json
    > Random Testing Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-30-17-27-56_Sim-Stack-Two-Step-Reward-Masked-Training/2020-07-04-08-05-41_Sim-Stack-Two-Step-Reward-Masked-Testing
    > Random Testing results:
    >  {'trial_success_rate_best_value': 1.0, 'trial_success_rate_best_index': 1321, 'grasp_success_rate_best_value': 0.8487394957983193, 'grasp_success_rate_best_index': 1321, 'place_success_rate_best_value': 0.7467105263157895, 'place_success_rate_best_index': 1321, 'action_efficiency_best_value': 0.45420136260408783, 'action_efficiency_best_index': 1321}
    > Training Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-30-17-27-56_Sim-Stack-Two-Step-Reward-Masked-Training
    > Training results:
    >  {'trial_success_rate_best_value': 0.8103448275862069, 'trial_success_rate_best_index': 6022, 'grasp_success_rate_best_value': 0.9153846153846154, 'grasp_success_rate_best_index': 12393, 'place_success_rate_best_value': 0.8297872340425532, 'place_success_rate_best_index': 8789, 'action_efficiency_best_value': 0.624, 'action_efficiency_best_index': 8820}





SIM ROW - Task Progress SPOT-Q MASKED - REWARD SCHEDULE 0.1, 1, 1 - EFFICIENTNET 1 dilation - workstation named spot 2020-06-30
----------------------------------------------------------------------------------------
export CUDA_VISIBLE_DEVICES="0" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 4 --push_rewards --experience_replay --explore_rate_decay --check_row --tcp_port 19990 --place --future_reward_discount 0.65 --max_train_actions 20000 --random_actions --common_sense --nn efficientnet --num_dilation 1
Creating data logging session: /home/ahundt/src/real_good_robot/logs/2020-06-30-17-46-54_Sim-Rows-Two-Step-Reward-Masked-Training
Commit: cca5887217884d862167edbf31ffaf4d1d21a863  release tag:v0.16.5
GPU 0, Tab 0, port 19990, left v-rep window, v-rep tab 7


    > Trial logging complete: 101 --------------------------------------------------------------
    > prev_height: 0.0 max_z: 0.05112317412691904 goal_success: True needed to reset: False max_workspace_height: -0.02 <<<<<<<<<<<
    > check_row: True | row_size: 2 | blocks: ['blue' 'red']
    > check_stack() stack_height: 2 stack matches current goal: True partial_stack_success: True Does the code think a reset is needed: False
    > STACK:  trial: 101 actions/partial: 3.7033492822966507  actions/full stack: 7.818181818181818 (lower is better)  Grasp Count: 411, grasp success rate: 0.8880778588807786 place_on_stack_rate: 0.5757575757575758 place_attempts: 363  partial_stack_successes: 209  stack_successes: 99 trial_success_rate: 0.9801980198019802 stack goal: [3 0] current_height: 2
    > trial_complete_indices: [  2.  16.  24.  80.  82.  86. 100. 105. 109. 113. 120. 139. 149. 162.
    >  164. 172. 176. 187. 191. 197. 203. 208. 210. 214. 216. 220. 230. 234.
    >  238. 242. 251. 253. 257. 267. 275. 279. 284. 290. 312. 318. 324. 328.
    >  334. 338. 344. 349. 355. 359. 363. 368. 372. 380. 382. 388. 394. 400.
    >  404. 409. 413. 415. 419. 425. 440. 446. 454. 458. 470. 474. 476. 482.
    >  588. 592. 594. 596. 600. 609. 611. 615. 621. 642. 650. 654. 662. 670.
    >  680. 685. 689. 693. 698. 702. 704. 706. 719. 723. 730. 734. 738. 746.
    >  750. 760. 773.]
    > Max trial success rate: 0.98, at action iteration: 770. (total of 772 actions, max excludes first 770 actions)
    > Max grasp success rate: 0.8899755501222494, at action iteration: 770. (total of 772 actions, max excludes first 770 actions)
    > Max place success rate: 0.787292817679558, at action iteration: 770. (total of 773 actions, max excludes first 770 actions)
    > Max action efficiency: 0.7636363636363637, at action iteration: 770. (total of 773 actions, max excludes first 770 actions)
    > saving trial success rate: /home/ahundt/src/real_good_robot/logs/2020-07-04-12-12-29_Sim-Rows-Two-Step-Reward-Masked-Testing/transitions/trial-success-rate.log.csv
    > saving grasp success rate: /home/ahundt/src/real_good_robot/logs/2020-07-04-12-12-29_Sim-Rows-Two-Step-Reward-Masked-Testing/transitions/grasp-success-rate.log.csv
    > saving place success rate: /home/ahundt/src/real_good_robot/logs/2020-07-04-12-12-29_Sim-Rows-Two-Step-Reward-Masked-Testing/transitions/place-success-rate.log.csv
    > saving action efficiency: /home/ahundt/src/real_good_robot/logs/2020-07-04-12-12-29_Sim-Rows-Two-Step-Reward-Masked-Testing/transitions/action-efficiency.log.csv
    > saving plot: 2020-07-04-12-12-29_Sim-Rows-Two-Step-Reward-Masked-Testing-Sim-Rows-Two-Step-Reward-Masked-Testing_success_plot.png
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-07-04-12-12-29_Sim-Rows-Two-Step-Reward-Masked-Testing/data/best_stats.json
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-07-04-12-12-29_Sim-Rows-Two-Step-Reward-Masked-Testing/best_stats.json
    > Random Testing Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-30-17-46-54_Sim-Rows-Two-Step-Reward-Masked-Training/2020-07-04-12-12-29_Sim-Rows-Two-Step-Reward-Masked-Testing
    > Random Testing results:
    >  {'trial_success_rate_best_value': 0.98, 'trial_success_rate_best_index': 770, 'grasp_success_rate_best_value': 0.8899755501222494, 'grasp_success_rate_best_index': 770, 'place_success_rate_best_value': 0.787292817679558, 'place_success_rate_best_index': 770, 'action_efficiency_best_value': 0.7636363636363637, 'action_efficiency_best_index': 770}
    > Training Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-30-17-46-54_Sim-Rows-Two-Step-Reward-Masked-Training
    > Training results:
    >  {'trial_success_rate_best_value': 0.7446808510638298, 'trial_success_rate_best_index': 18005, 'grasp_success_rate_best_value': 0.8555555555555555, 'grasp_success_rate_best_index': 16054, 'place_success_rate_best_value': 0.7981651376146789, 'place_success_rate_best_index': 19487, 'action_efficiency_best_value': 1.008, 'action_efficiency_best_index': 19499}





SIM ROW - SPOT STANDARD Trial rtrial Task Progress - TRIAL REWARD - REWARD SCHEDULE 0.1, 1, 1 - EFFICIENTNET 1 dilation - workstation named spot 2020-07-01
----------------------------------------------------------------------------------------
export CUDA_VISIBLE_DEVICES="3" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 4 --push_rewards --experience_replay --explore_rate_decay --check_row --tcp_port 20000 --place --future_reward_discount 0.65 --max_train_actions 20000 --random_actions --common_sense --nn efficientnet --num_dilation 1 --trial_reward
Creating data logging session: /home/ahundt/src/real_good_robot/logs/2020-07-01-17-41-43_Sim-Rows-SPOT-Trial-Reward-Masked-Training
Commit: cca5887217884d862167edbf31ffaf4d1d21a863  release tag:v0.16.5
GPU 3, Tab 3, port 20000, right v-rep window, v-rep tab 10

    > Trial logging complete: 101 --------------------------------------------------------------
    > STACK:  trial: 101 actions/partial: 3.719665271966527  actions/full stack: 9.98876404494382 (lower is better)  Grasp Count: 474, grasp success rate: 0.9008438818565401 place_on_stack_rate: 0.5759036144578313 place_attempts: 415  partial_stack_successes: 239  stack_successes: 89 trial_success_rate: 0.8811881188118812 stack goal: [0 3] current_height: 2
    > trial_complete_indices: [  2.   9.  15.  20.  24.  32.  55.  62.  67.  71.  83. 103. 115. 117.
    >  125. 133. 141. 147. 158. 164. 174. 183. 193. 199. 208. 214. 234. 238.
    >  242. 259. 265. 280. 286. 290. 296. 304. 308. 319. 325. 333. 341. 345.
    >  368. 372. 378. 382. 388. 402. 418. 442. 448. 454. 458. 467. 471. 473.
    >  481. 492. 496. 505. 509. 515. 519. 540. 548. 566. 570. 577. 583. 589.
    >  593. 599. 601. 632. 640. 648. 671. 675. 711. 719. 730. 738. 742. 748.
    >  750. 752. 758. 764. 768. 774. 783. 821. 825. 829. 837. 846. 854. 860.
    >  870. 880. 888.]
    > Max trial success rate: 0.88, at action iteration: 885. (total of 887 actions, max excludes first 885 actions)
    > Max grasp success rate: 0.902542372881356, at action iteration: 885. (total of 887 actions, max excludes first 885 actions)
    > Max place success rate: 0.7198067632850241, at action iteration: 885. (total of 888 actions, max excludes first 885 actions)
    > Max action efficiency: 0.6169491525423729, at action iteration: 885. (total of 888 actions, max excludes first 885 actions)
    > saving trial success rate: /home/ahundt/src/real_good_robot/logs/2020-07-05-17-34-39_Sim-Rows-SPOT-Trial-Reward-Masked-Testing/transitions/trial-success-rate.log.csv
    > saving grasp success rate: /home/ahundt/src/real_good_robot/logs/2020-07-05-17-34-39_Sim-Rows-SPOT-Trial-Reward-Masked-Testing/transitions/grasp-success-rate.log.csv
    > saving place success rate: /home/ahundt/src/real_good_robot/logs/2020-07-05-17-34-39_Sim-Rows-SPOT-Trial-Reward-Masked-Testing/transitions/place-success-rate.log.csv
    > saving action efficiency: /home/ahundt/src/real_good_robot/logs/2020-07-05-17-34-39_Sim-Rows-SPOT-Trial-Reward-Masked-Testing/transitions/action-efficiency.log.csv
    > saving plot: 2020-07-05-17-34-39_Sim-Rows-SPOT-Trial-Reward-Masked-Testing-Sim-Rows-SPOT-Trial-Reward-Masked-Testing_success_plot.png
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-07-05-17-34-39_Sim-Rows-SPOT-Trial-Reward-Masked-Testing/data/best_stats.json
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-07-05-17-34-39_Sim-Rows-SPOT-Trial-Reward-Masked-Testing/best_stats.json
    > Random Testing Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-07-01-17-41-43_Sim-Rows-SPOT-Trial-Reward-Masked-Training/2020-07-05-13-47-48_Sim-Rows-SPOT-Trial-Reward-Masked-Testing
    > Random Testing results:
    >  {'trial_success_rate_best_value': 0.9, 'trial_success_rate_best_index': 772, 'grasp_success_rate_best_value': 0.8776978417266187, 'grasp_success_rate_best_index': 772, 'place_success_rate_best_value': 0.7471910112359551, 'place_success_rate_best_index': 772, 'action_efficiency_best_value': 0.7072538860103627, 'action_efficiency_best_index': 772}
    > Training Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-07-01-17-41-43_Sim-Rows-SPOT-Trial-Reward-Masked-Training
    > Training results:
    >  {'trial_success_rate_best_value': 0.7078651685393258, 'trial_success_rate_best_index': 19445, 'grasp_success_rate_best_value': 0.8555555555555555, 'grasp_success_rate_best_index': 18899, 'place_success_rate_best_value': 0.7663551401869159, 'place_success_rate_best_index': 19900, 'action_efficiency_best_value': 0.828, 'action_efficiency_best_index': 19904}
